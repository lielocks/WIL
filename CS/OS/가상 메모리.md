# 개요

**메모리 Memory 란?**

+ 메모리란 프로그램과 프로그램 수행에 필요한 데이터 및 코드를 저장하는 장치임.

+ 메모리는 크게 **내부 기억장치** 인 **`주기억장치`** 와 **외부 기억장치** 인 **`보조 기억장치`** 로 분류됨.
  + DRAM, CPU 안에 있는 레지스터 (register) 와 캐쉬 (cache memory) 등이 전자에 해당됨.
  + SSD, HDD 등이 후자에 해당됨.

<br>

## 가상 메모리 등장 배경
+ 초창기 컴퓨터에서는 사용 가능한 RAM 의 용량이, 가장 큰 실행 어플리케이션의 주소 공간보다 커야 했음.
  그렇지 않을 경우 "메모리 부족" 오류에 의해 해당 어플리케이션을 실행할 수 없었음.

+ 이후 컴퓨터에서는 프로그래머가 **애플리케이션의 일부분만 기억장치에 올려 실행** 하도록 지정할 수 있게 하는 **`오버레이 기법`** 을 사용하여 메모리 부족 문제를 해결하고자 했음.

  하지만 이 역시 전반적인 메모리 부족 문제를 해결할 수 없었음.

  오버레이를 사용하는 프로그램은 그렇지 않은 프로그램보다는 메모리를 덜 사용했지만, 애초에 시스템이 프로그램을 위한 충분한 메모리를 갖추고 있지 않은 경우에는 **결국 똑같은 메모리 부족 오류** 가 발생했음.

+ 여기에서 더 발전한 **`가상 메모리 기법`** 은 애플리케이션을 실행하는 데 얼마나 많은 메모리가 필요한지에 집중하지 않고, 대신 애플리케이션을 실행하는 데 **최소한** 얼마만큼의 메모리가 필요한가에 집중하여 문제를 해결하고자 함.
  + 이렇게 접근하는 방식이 가능한 이유는, 메모리 접근은 **`순차적이고 지역화`** 되어 있기 때문에
  + 그렇다면 이렇게 어플리케이션의 일부분만 메모리 (기억장치)에 올려진다면, 메모리에 올라가지 않는 나머지는 어디에 위치해야 할까 ? ⇒정담은 **보조 기억장치, 즉 디스크!**
  + 가상 메모리의 핵심은 **보조 기억장치** 이다.

<br>

## 가상 메모리란 ?
> **NOTE**
>
> 가상 메모리는 메모리가 실제 메모리보다 많아 보이게 하는 기술로,
>
> 어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 점에 착안하여 고안되었음.

<br>

+ 어플리케이션이 실행될 때, 실행에 필요한 일부분만 메모리에 올라가며 어플리케이션의 나머지는 디스크에 남게 됨.

  즉, 디스크가 RAM 의 보조기억장치 (backing store) 처럼 작동하는 것임.
  
  + 결국 빠르고 작은 기억장치 (RAM) 을 크고 느린 기억장치 (디스크) 와 병합하여, 하나의 크고 빠른 기억장치 (가상 메모리) 처럼 동작하게 하는 것임.

![image](https://github.com/lielocks/WIL/assets/107406265/2fd0d3b0-6ad0-49d7-8ef4-6a876fca86e1)

+ 가상 메모리를 구현하기 위해서는 컴퓨터가 특수 메모리 관리 hardware를 갖추고 있어야만 함.
  ⇒ 바로 **`MMU (Memory Management Unit)`** 

![image](https://github.com/lielocks/WIL/assets/107406265/f18142c9-934a-4691-a521-a19cae749e78)

+ MMU는 **`가상주소를 물리주소로 변환`** 하고, **`메모리를 보호`** 하는 기능을 수행함.

+ MMU를 사용하게 되면, CPU 가 각 메모리에 접근하기 이전에 **메모리 주소 번역 작업** 이 수행됨.

+ 그러나 메모리를 `일일이 가상 주소에서 물리적 주소로 번역` 하게 되면 작업 부하가 너무 높아지므로,
  MMU는 **RAM을 여러 부분(pages 페이지)** 로 나누어 각 페이지를 하나의 독립된 항목으로 처리함.

+ **`페이지 및 주소 번역 정보`** 를 기억하는 작업이 가상 메모리를 구현하는데 있어 결정적인 절차임.

**MMU 메커니즘**

1. **CPU** 는 가상 주소 접근 시 `MMU 장치` 를 통해 **물리 메모리를 접근**

2. 프로세스가 생성되면, `Page Table 정보` 가 생성됨
   1. PCB 등에서 해당 page table 접근이 가능하고, **관련 정보는 물리 메모리** 에 적재해요.
   2. 프로세스가 구동되면, 해당 **`page table base 주소`** 가 **별도 레지스토 CR3** 에 저장되어요.
   3. **CPU가 가상 주소를 접근** 하면 **MMU가 page table base 주소를 접근** 해서 `물리 주소` 를 가져와요.

<br>

## 요구 페이징 (demand paging) 이란?

> 요구 페이징은 **`CPU가 요청할 때`** 프로세스의 데이터를 메모리에 올리는 것을 의미함.
>
> 즉, **처음부터 모든 데이터를 메모리로 적재하지는 않음**

<br>

## 페이지 폴트 (page faults) 란?

> 페이지 폴트란 어떤 페이지에 접근하려고 했을 때 **해당 페이지가 실제 물리 메모리에 부재** 할 때 뜨는 **`인터럽트`** 이며,
>
> 페이지 폴트가 발생하면 **운영체제가 이를 해결한 뒤 다시 동일한 명령을 수행** 하는 식으로 동작함.

![image](https://github.com/lielocks/WIL/assets/107406265/85d3edb7-3bef-4bb8-b36e-eadc6c61fbb5)

+ 페이지 폴트란, 어떤 프로그램이 **자신의 주소 공간 (가상 메모리 공간) 에는 존재** 하지만 **시스템의 RAM에는 현재 존재하지 않는 데이터/코드에 접근을 시도할 경우** 발생하는 현상을 의미함.

+ 페이지 폴트가 발생하면 **OS 는 그 데이터를 메모리로 가져와서,** `마치 페이지 폴트가 전혀 발생하지 않은 것처럼 프로그램이 계속적으로 작동` 하게 해줌.

+ 이러한 페이지 폴트가 자주 일어날수록 OS의 성능이 많이 저하기되기 때문에 페이지 폴트가 일어나지 않도록 하는 것이 중요.

  페이지 폴트를 최소화하기 위한 방법으로는 **페이지 교체 정책 (page replacement policy)** 가 있음

  + 메모리가 꽉 차있을때 기존 페이지 중 하나를 물리 메모리에서 저장 매체로 내리고, 
    새로운 페이지를 방금 비워진 해당 물리 메모리 공간에 올림.
    이때 기존 페이지 중 어떤 것을 내리면 좋을지에 대한 알고리즘을 짠 것이 바로 `페이지 교체 알고리즘` 인 것!

<br>

## 스레싱 Thrashing
프로세스가 집중적으로 사용하는 페이지들의 집합이 **메모리에 한꺼번에 적재되지 못하여** 페이지 부재율(page fault)가 많이 발생하게 되고 **CPU 이용율이 급격히 떨어지는 현상** 을 스레싱이라고 합니다.
 
`CPU 이용율이 낮다` 는 것은 `메모리에 올라와 있는 프로세스의 수가 너무 적어` **프로세스가 모두 I/O작업을 함으로써** **`준비 큐가 비는 경우가 발생했다`** 는 것입니다. 

따라서 CPU 이용율이 낮으면 **운영체제는 메모리에 올라가는 프로세스의 수를 늘리게 됩니다.**

우리는 메모리에 동시에 올라가 있는 프로세스의 수를 **`다중 프로그래밍의 정도(MPD: Multi-Programming Degree)`** 라고 부릅니다.

<br>

### 스레싱은 어떻게 발생하는 걸까?

![image](https://github.com/lielocks/WIL/assets/107406265/9db4c94c-2ac6-40c7-bdb2-b7826506ab48)

운영체제는 **`CPU 이용률이 낮으면`** **MPD를 높입니다.** 
그러나 **과도하게 MPD가 높아지면** **`프로세스에게 할당되는 메모리의 양이 감소`** 하게 될 것입니다. 

프로세스가 원활하게 수행하려면 필요한 **`최소한의 페이지 프레임들`** 이 있습니다. 그러면 각 프로세스는 `수행에 필요한 최소한의 페이지 프레임도 할당 받지 못하게 되어`  **페이지 부재가 빈번히 발생** 하게 될 것입니다. 
페이지 부재가 발생하면 `스왑 영역` 에서 **해당 페이지를 메모리로 가져오기 위해** **`디스크 I/O 작업이 발생`** 하고 **`문맥 교환을 통해 다른 프로세스에게 CPU가 이양`** 됩니다. 

이때 다른 프로세스 역시 `할당 받은 메모리 양이 지나치게 적으면` 페이지 부재가 발생할 수밖에 없게 됩니다. 
그러면 또 `다른 프로세스에게 CPU가 할당` 된다. 
결국에는 **`준비 큐에 있는 모든 프로세스에게 CPU가 한 차례씩 할당되었는데도`** 모든 프로세스가 다 페이지 부재를 발생시켜 `시스템은 페이지 부재를 처리하느라 매우 분주` 해지고 **CPU 이용률은 급격히 떨어지게 된다.** 

이 상황에서 `운영체제` 는 **메모리에 올라와 있는 프로세스의 수가 적어 이러한 현상이 발생했다고 판단** 하고, **`MPD를 높이기 위해 또 다른 프로세스를 메모리에 추가`** 하게 된다. 
이로 인해 **프로세스당 할당된 프레임의 수가 더욱 감소** 하고 ***페이지 부재는 더욱 빈번히 발생하게 된다.*** 

이 경우 프로세스들은 `서로의 페이지를 교체` 하며 **스왑 인(swap in)** 과 **스왑 아웃(swap out)** 을 지속적으로 발생시키고, **`CPU는 대부분의 시간에 일을 하지 않게 됩니다.`** 

<br>

### 스레싱 발생 방지 알고리즘
**MPD를 적절히 조절** 하여 `CPU 이용률을 높이면서 스레싱이 발생하는 것을 막는 방법` 으로 워킹셋 알고리즘과 페이지 부재 빈도 알고리즘이 있습니다.
 
**1. 워킹셋 알고리즘**

프로세스가 일정 시간 동안 집중적으로 특정 주소 영역을 참조하는 경향이 있는데 이를 **`지역성 집합`**이라고 합니. 

워킹셋 알고리즘은 **지역성 집합이 메모리에 동시에 올라갈 수 있도록 보장** 하는 메모리 관리 알고리즘입니다.
 
`워킹셋` 은 `한꺼번에 메모리에 올라가야 하는 페이지들의 집합` 입니다. 
워킹셋 알고리즘은 프로세스의 **워킹셋을 구성하는 페이지들이 한꺼번에 올라갈 수 있을 메모리 공간이 있을 때만** 동작합니다. 
그렇지 않으면 `기존 메모리에 존재하는 페이지` 를 **디스크로 스왑 아웃 시켜 공간을 확보** 합니다. 
이러한 방법으로 **`MPD를 조절하고 스레싱을 방지`** 하게 됩니다.
 
![image](https://github.com/lielocks/WIL/assets/107406265/e189e378-ce8a-4111-ab39-2093ea43f61e)

워킹셋 알고리즘에서 ***한꺼번에 메모리에 올라가야 할 페이지들의 집합*** 을 결정하기 위해 **`워킹셋 윈도우`** 를 사용합니다. 
`윈도우의 크기` 를 **Δ** 라고 합니다. 
워킹셋 알고리즘은 시각 t에서 Δ이전에 참조된 **[Δ-t, t] 사이에 참조된 페이지들의 집합** 으로 결정한다.
 
워킹셋 윈도우의 크기를 조절하여 워킹셋의 크기를 조절하는 방법으로 프로세스가 메모리를 필요로 할때는 많이 할당하고 적게 필요로 할 때에는 적게 할당하는 **동적인 프레임 할당 기능** 을 수행하게 됩니다.

<br>

**2. 페이지 부재 빈도 알고리즘**
프로세스의 **페이지 부재율을 주기적으로 조사** 하고 이 값에 근거해서 ***각 프로세스에 할당할 메모리 양을 동적으로 조절*** 하는 알고리즘입니다. 

시스템이 미리 정해 놓은 `상한값(upper bound)을 넘어가거나` `하한값(lower bound)이하로 떨어지게 되면` 운영체제가 **메모리에 올라가 있는 프로세스의 수를 조절** 하게 됩니다.

![image](https://github.com/lielocks/WIL/assets/107406265/588b21e9-39f2-45f5-8ed1-fb4f2f013d4f)

<br>

## TLB (Translation Lookaside Buffer 페이지 정보 캐쉬) 란?
> TLB 는 가상 메모리 주소를 물리적 주소로 **변환하는 속도를 높이기 위해 사용하는 캐시** 로, 최근에 일어난 **`가상 메모리와 물리 주소의 변환 테이블`** 을 저장해둠.
>
> CPU가 가상 주소를 가지고 메모리에 접근하려고 할 때 우선은 TLB에 접근하여 가상 주소에 해당되는 물리 주소를 찾고,
>
> 만약 TLB에 매핑이 존재하지 않는다면 MMU가 페이지 테이블에서 해당되는 물리 주소로 변환한 후 메모리에 접근하게 됨.
>
> *buffer - 컴퓨터의 완충 기억 장치

<br>

실제 메모리 주소를 접근할 때 **`MMU`** 를 활용한다고 했는데,

실은 추가적으로 하드웨어 보조장치를 활용해서 접근하는데, 

이를 **`Translation Lookaside Buffer, TLB`** 라고 해요.

![image](https://github.com/lielocks/WIL/assets/107406265/dcc6bcc2-0b37-4621-b32e-c5bb9e772f82)

<br>

그림에서 알 수 있듯이, 메인 메모리 접근시간보다 **레지스터 접근 시간** 이 현저하게 빨라요. 

그래서 데이터 접근할 때마다 메인 메모리보단 과거에 사용한 적이 있다면 이를 따로 **`레지스터에 캐싱Caching`** 해서 접근 속도를 높이는 보조장치를 두는 TLB, 
페이지 정보 캐시 장치로 접근 속도 향상을 시킬 수 있게 하기 위해 따로 보조장치를 두는 거에요.

![image](https://github.com/lielocks/WIL/assets/107406265/3b26093e-3421-4591-81b3-c5d799d52e42)

<br>

**매커니즘 with TLB**

1. 가상 주소 요청 → **`MMU`**
2. **`MMU`** 는 **TLB에서 최근에 가상 주소에서 물리 주소로 변환한 정보가 있는지** 확인, 있다면 해당 정보를 활용!
3. TLB에 없다면 `CR3에 등록된 base 주소로 접근` 해 **메인 메모리에서 데이터** 를 찾아요.
4. 찾았다면 메인 메모리는 **MMU에 `물리 주소` 를 반환** 시켜줘요.
5. 그리고 MMU는 해당 정보를 **TLB에 캐싱** 하고 이 **물리 주소를 기반으로 메인 메모리에 접근** 해요.
6. 그리고 **`메인 메모리`** 는 **해당 데이터를 CPU에 적재시켜서 프로세스를 수행** 해요.

<br>

+ **TLB** 는 MMU에 포함되어 있는 작은 캐시로, 일종의 **주소 변환 캐시** 라고 할 수 있음.

  + 참고 : **캐시 메모리 cache memory** 란?
    + 캐시 메모리란, 속도가 빠른 장치와 느린 장치 사이에서 속도 차에 따른 병목 현상을 줄이기 위한 범용 메모리를 의미함.
      예를 들어, CPU 에서의 캐시 메모리는 CPU 코어(고속)와 메모리(CPU에 비해 저속) 사이에서 속도 차에 따른 병목 현상을 완화하는 역할을 함.

    + 또한, 인터넷 웹 브라우저에서는 캐시 파일이라는 개념이 있는데 캐시 파일은 웹 페이지 상의 이미지 등을 하드디스크에 미리 저장해두고,

      다음 번에도 해당 웹 페이지에 접근할 때 해당 사이트에 이미지를 다시 요청하는 게 아니라 하드디스크에서 이미지를 불러들여 로딩 속도를 높이는 역할을 함.

      즉 캐시 파일은 비교적 속도가 빠른 하드디스크과 상대적으로 느린 웹 페이지 가운데서의 병목을 줄이는 역할을 함.

  + TLB 사용 이점 : **물리 주소를 가지고 있으면** 메모리(RAM)에 두번 들릴 필요 없이, **바로 해당 물리 주소** (in메모리) 를 찾아갈 수 있음.

<br>

## 페이징 시스템
실제로 프로세스는 4GB 를 넘는 경우가 거의 없어요.

우리가 간단하게 Hello World!를 출력하는 프로그램부터 해서, 대부분 프로세스는 4GB까지 공간을 필요로 하지 않아요. 

따라서 하나의 프로세스가 4GB를 모두 차지하는 것은 매우 비효율적이에요.

그래서 페이지 정보를 단계로 나눠서 생성해요. 필요 없는 페이지를 생성하지 않으면 그만큼 공간 절약이 가능해요.

> **32-bit 시스템에서 4KB를 위한 페이징 시스템**
>
> 하위 12 bit 는 **오프셋** , 상위 20 bit 는 페이징 번호 이므로,
>
> 2의 20승 (1048576)개의 페이지 정보가 필요해요.

![image](https://github.com/lielocks/WIL/assets/107406265/e1a8e6a6-d778-4d5b-b08d-90b54a87c4c3)

공간 절약을 위해 위와 같이 페이지 번호를 나타내는 **bit** 를 구분해서 단계를 나눠요.

본래 상위 20 bit를 페이지 정보로 활용했지만, 이렇게 단계를 나눠 상단의 10 bit는 페이지 경로 **`Page Directory`** 그 다음 10 bit 는 **실제로 사용하는 ** **`Page Table`** 로 나눠 효율적인 공간 관리하는 시스템을 구축했어요.

**`CR3 레지스터`** 에 Page Directory 시작 주소를 등록하여 찾아가고,

Page Directory에는 Page Table 의 시작 주소를 가지고 있어 Page Table 에 접근해 

실제 물리 메모리의 프레임 주소를 찾아 데이터를 가져오는 방식이에요.

그림 상에서는 3단계이지만 linux 에서는 4단계까지 나눈다고 합니다.

<br>

## 페이징 시스템과 공유 메모리
프로세스는 **동일한 물리 주소** 를 가리킬 수 있어요.

실행 중인 프로세스들이 서로 동일한 로직을 수행한다면 **굳이 따로 메모리에 적재돼서 실행될 거 없이 동일한 공간** 에서 프로세스를 수행하는 거에요.

이렇게 되면 당연히 `따로 공간을 만들지 않으니 메모리 절약` 이 되어요.

![image](https://github.com/lielocks/WIL/assets/107406265/6d331853-5c83-402a-82a4-e53e721a9fc6)

**`fork()`** 는 실행 중인 프로세스에게 동일한 자식 프로세스를 만들어줘요.

동일하니까 로직도 같으니 **`read`** 만 수행한다면 따로 메모리 공간을 할당시킬 필요가 없어, 동일한 공간에서 로직을 수행해요.

이러면 공간 절약 + 메모리 할당 시간도 모두 절약이 되어요.

<br>

![image](https://github.com/lielocks/WIL/assets/107406265/f2306eef-c176-4970-95ec-b88ea60e160c)

다만, 특정 프로세스에서 **`write`**, 물리 주소에서 데이터가 변경되면 두 프로세스는 서로 다른 로직을 수행해요.

그래서 물리 주소 복사를 이때 수행해서 필요할 때만 공간 할당을 수행해서 효율성을 높여요.

이를 **copy-on-write** 라고 해요.










