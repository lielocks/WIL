# 개요

**메모리 Memory 란?**

+ 메모리란 프로그램과 프로그램 수행에 필요한 데이터 및 코드를 저장하는 장치임.

+ 메모리는 크게 **내부 기억장치** 인 **`주기억장치`** 와 **외부 기억장치** 인 **`보조 기억장치`** 로 분류됨.
  + DRAM, CPU 안에 있는 레지스터 (register) 와 캐쉬 (cache memory) 등이 전자에 해당됨.
  + SSD, HDD 등이 후자에 해당됨.

<br>

## 가상 메모리 등장 배경
+ 초창기 컴퓨터에서는 사용 가능한 RAM 의 용량이, 가장 큰 실행 어플리케이션의 주소 공간보다 커야 했음.
  그렇지 않을 경우 "메모리 부족" 오류에 의해 해당 어플리케이션을 실행할 수 없었음.

+ 이후 컴퓨터에서는 프로그래머가 **애플리케이션의 일부분만 기억장치에 올려 실행** 하도록 지정할 수 있게 하는 **`오버레이 기법`** 을 사용하여 메모리 부족 문제를 해결하고자 했음.

  하지만 이 역시 전반적인 메모리 부족 문제를 해결할 수 없었음.

  오버레이를 사용하는 프로그램은 그렇지 않은 프로그램보다는 메모리를 덜 사용했지만, 애초에 시스템이 프로그램을 위한 충분한 메모리를 갖추고 있지 않은 경우에는 **결국 똑같은 메모리 부족 오류** 가 발생했음.

+ 여기에서 더 발전한 **`가상 메모리 기법`** 은 애플리케이션을 실행하는 데 얼마나 많은 메모리가 필요한지에 집중하지 않고, 대신 애플리케이션을 실행하는 데 **최소한** 얼마만큼의 메모리가 필요한가에 집중하여 문제를 해결하고자 함.
  + 이렇게 접근하는 방식이 가능한 이유는, 메모리 접근은 **`순차적이고 지역화`** 되어 있기 때문에
  + 그렇다면 이렇게 어플리케이션의 일부분만 메모리 (기억장치)에 올려진다면, 메모리에 올라가지 않는 나머지는 어디에 위치해야 할까 ? ⇒정담은 **보조 기억장치, 즉 디스크!**
  + 가상 메모리의 핵심은 **보조 기억장치** 이다.

<br>

## 가상 메모리란 ?
> **NOTE**
>
> 가상 메모리는 메모리가 실제 메모리보다 많아 보이게 하는 기술로,
>
> 어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 점에 착안하여 고안되었음.

<br>

+ 어플리케이션이 실행될 때, 실행에 필요한 일부분만 메모리에 올라가며 어플리케이션의 나머지는 디스크에 남게 됨. 즉, 디스크가 RAM 의 보조기억장치 (backing store) 처럼 작동하는 것임.
  + 결국 빠르고 작은 기억장치 (RAM) 을 크고 느린 기억장치 (디스크) 와 병합하여, 하나의 크고 빠른 기억장치 (가상 메모리) 처럼 동작하게 하는 것임.

![image](https://github.com/lielocks/WIL/assets/107406265/2fd0d3b0-6ad0-49d7-8ef4-6a876fca86e1)

+ 가상 메모리를 구현하기 위해서는 컴퓨터가 특수 메모리 관리 hardware를 갖추고 있어야만 함.
  ⇒ 바로 **`MMU (Memory Management Unit)`** 

![image](https://github.com/lielocks/WIL/assets/107406265/f18142c9-934a-4691-a521-a19cae749e78)

+ MMU는 **`가상주소를 물리주소로 변환`** 하고, **`메모리를 보호`** 하는 기능을 수행함.

+ MMU를 사용하게 되면, CPU 가 각 메모리에 접근하기 이전에 **메모리 주소 번역 작업** 이 수행됨.

+ 그러나 메모리를 `일일이 가상 주소에서 물리적 주소로 번역` 하게 되면 작업 부하가 너무 높아지므로,
  MMU는 **RAM을 여러 부분(pages 페이지)** 로 나누어 각 페이지를 하나의 독립된 항목으로 처리함.

+ **`페이지 및 주소 번역 정보`** 를 기억하는 작업이 가상 메모리를 구현하는데 있어 결정적인 절차임.

**MMU 메커니즘**

1. **CPU** 는 가상 주소 접근 시 `MMU 장치` 를 통해 **물리 메모리를 접근**

2. 프로세스가 생성되면, `Page Table 정보` 가 생성됨
   1. PCB 등에서 해당 page table 접근이 가능하고, **관련 정보는 물리 메모리** 에 적재해요.
   2. 프로세스가 구동되면, 해당 **`page table base 주소`** 가 **별도 레지스토 CR3** 에 저장되어요.
   3. **CPU가 가상 주소를 접근** 하면 **MMU가 page table base 주소를 접근** 해서 `물리 주소` 를 가져와요.

<br>

## 요구 페이징 (demand paging) 이란?

> 요구 페이징은 **`CPU가 요청할 때`** 프로세스의 데이터를 메모리에 올리는 것을 의미함.
>
> 즉, **처음부터 모든 데이터를 메모리로 적재하지는 않음**

<br>

## 페이지 폴트 (page faults) 란?

> 페이지 폴트란 어떤 페이지에 접근하려고 했을 때 **해당 페이지가 실제 물리 메모리에 부재** 할 때 뜨는 **`인터럽트`** 이며,
>
> 페이지 폴트가 발생하면 **운영체제가 이를 해결한 뒤 다시 동일한 명령을 수행** 하는 식으로 동작함.

+ 페이지 폴트란, 어떤 프로그램이 **자신의 주소 공간 (가상 메모리 공간) 에는 존재** 하지만 **시스템의 RAM에는 현재 존재하지 않는 데이터/코드에 접근을 시도할 경우** 발생하는 현상을 의미함.

+ 페이지 폴트가 발생하면 **OS 는 그 데이터를 메모리로 가져와서,** `마치 페이지 폴트가 전혀 발생하지 않은 것처럼 프로그램이 계속적으로 작동` 하게 해줌.

+ 이러한 페이지 폴트가 자주 일어날수록 OS의 성능이 많이 저하기되기 때문에 페이지 폴트가 일어나지 않도록 하는 것이 중요.

  페이지 폴트를 최소화하기 위한 방법으로는 **페이지 교체 정책 (page replacement policy)** 가 있음

  + 메모리가 꽉 차있을때 기존 페이지 중 하나를 물리 메모리에서 저장 매체로 내리고, 
    새로운 페이지를 방금 비워진 해당 물리 메모리 공간에 올림.
    이때 기존 페이지 중 어떤 것을 내리면 좋을지에 대한 알고리즘을 짠 것이 바로 `페이지 교체 알고리즘` 인 것!

<br>

## TLB (Translation Lookaside Buffer 페이지 정보 캐쉬) 란?
> TLB 는 가상 메모리 주소를 물리적 주소로 **변환하는 속도를 높이기 위해 사용하는 캐시** 로, 최근에 일어난 **`가상 메모리와 물리 주소의 변환 테이블`** 을 저장해둠.
>
> CPU가 가상 주소를 가지고 메모리에 접근하려고 할 때 우선은 TLB에 접근하여 가상 주소에 해당되는 물리 주소를 찾고,
>
> 만약 TLB에 매핑이 존재하지 않는다면 MMU가 페이지 테이블에서 해당되는 물리 주소로 변환한 후 메모리에 접근하게 됨.
>
> *buffer - 컴퓨터의 완충 기억 장치

![image](https://github.com/lielocks/WIL/assets/107406265/dcc6bcc2-0b37-4621-b32e-c5bb9e772f82)

<br>

그림에서 알 수 있듯이, 메인 메모리 접근시간보다 **레지스터 접근 시간** 이 현저하게 빨라요. 

그래서 데이터 접근할 때마다 메인 메모리보단 과거에 사용한 적이 있다면 이를 따로 **`레지스터에 캐싱Caching`** 해서 접근 속도를 높이는 보조장치를 두는 TLB, 
페이지 정보 캐시 장치로 접근 속도 향상을 시킬 수 있게 하기 위해 따로 보조장치를 두는 거에요.

![image](https://github.com/lielocks/WIL/assets/107406265/3b26093e-3421-4591-81b3-c5d799d52e42)

<br>

**매커니즘 with TLB**

1. 가상 주소 요청 → MMU
2. **`MMU`** 는 **TLB에서 최근에 가상 주소에서 물리 주소로 변환한 정보가 있는지** 확인, 있다면 해당 정보를 활용!
3. TLB에 없다면 `CR3에 등록된 base 주소로 접근` 해 **메인 메모리에서 데이터** 를 찾아요.
4. 찾았다면 메인 메모리는 **MMU에 `물리 주소` 를 반환** 시켜줘요.
5. 그리고 MMU는 해당 정보를 **TLB에 캐싱** 하고 이 **물리 주소를 기반으로 메인 메모리에 접근** 해요.
6. 그리고 **`메인 메모리`** 는 **해당 데이터를 CPU에 적재시켜서 프로세스를 수행** 해요.

<br>

+ **TLB** 는 MMU에 포함되어 있는 작은 캐시로, 일종의 **주소 변환 캐시** 라고 할 수 있음.

  + 참고 : **캐시 메모리 cache memory** 란?
    + 캐시 메모리란, 속도가 빠른 장치와 느린 장치 사이에서 속도 차에 따른 병목 현상을 줄이기 위한 범용 메모리를 의미함.
      예를 들어, CPU 에서의 캐시 메모리는 CPU 코어(고속)와 메모리(CPU에 비해 저속) 사이에서 속도 차에 따른 병목 현상을 완화하는 역할을 함.

    + 또한, 인터넷 웹 브라우저에서는 캐시 파일이라는 개념이 있는데 캐시 파일은 웹 페이지 상의 이미지 등을 하드디스크에 미리 저장해두고,

      다음 번에도 해당 웹 페이지에 접근할 때 해당 사이트에 이미지를 다시 요청하는 게 아니라 하드디스크에서 이미지를 불러들여 로딩 속도를 높이는 역할을 함.

      즉 캐시 파일은 비교적 속도가 빠른 하드디스크과 상대적으로 느린 웹 페이지 가운데서의 병목을 줄이는 역할을 함.

  + TLB 사용 이점 : **물리 주소를 가지고 있으면** 메모리(RAM)에 두번 들릴 필요 없이, **바로 해당 물리 주소** (in메모리) 를 찾아갈 수 있음.
