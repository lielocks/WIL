# Process & Thread 개념
![image](https://github.com/lielocks/WIL/assets/107406265/20a7d582-c988-4a20-95fb-df1b90f02b7f)

일단 Process 의 **작업의 단위** 라는 단어와 Thread 의 **실행 흐름의 단위** 라는 단어를 기억해 두고 글을 읽어보자.

<br>

## Program 과 Process

### 정적 프로그램 (Static Program)

컴퓨터 전공이 아니라서 'Process' 라는 명칭은 낯설수 있는데, 'Program' 은 친숙하리라 생각된다.

Program 은 윈도우의 `*.exe` 파일이나 Mac의 `*.dmg` 파일과 같은 **컴퓨터에서 실행 할 수 있는 파일** 을 통칭한다. 

단, 아직 **파일을 실행하지 않은 상태** 이기 때문에 **정적 프로그램(Static Program)** 줄여서 **`프로그램(Program)`** 이라고 부른 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/1918ecd9-048f-4a5e-9895-c92481cb878f)

어떠한 Program 을 개발하기 위해선 Java 나 C언어와 같은 언어를 이용해 코드를 작성하여 완성된다.

즉, Program 은 쉽게 말해서 그냥 **코드 덩어리** 인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/cd47d329-23af-45bf-a19f-cbf285d1e9b3)

<br>

### 프로세스 Process

Program 이 그냥 코드 덩어리이면, **`Process`** 는 Program 을 실행 시켜 Static Program 이 동적(動的)으로 변하여 **프로그램이 돌아가고 있는 상태** 를 말한다.

즉, 컴퓨터에서 **작업** 중인 Program 을 의미하는 것이다.

이 개념은 절대 생소한 것이 아니다.

`ctrl + alt + del` 단축키를 눌러 우리가 항상 보던 '작업' 관리자를 열어보면 개념이 고대로 들어있는걸 볼 수 있을 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/14b92a3c-0f72-4274-b97c-975281bdf355)

모든 Program 은 운영체제가 실행되기 위한 Memory 공간을 할당해 줘야 실행될 수 있다.

그래서 Program 을 실행하는 순간 *파일은 컴퓨터 Memory 에 올라가게 되고,* OS 로부터 *시스템 자원 (CPU) 를 할당*받아 Program 코드를 실행시켜 우리가 서비스를 이용할 수 있게 되는 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/8b791514-4cd2-4c79-a32f-8f87776bc739)

똑같은 어플리케이션을 실행 하냐 안하냐 차이일 뿐이라서, 일반적으로 Process 와 Program 을 같은 개념으로 이야기할 때가 많지만, 이 둘은 다른 개념인 것이다.

최종적으로 이 둘을 간단 명료하게 정리하면 아래 표와 같다.

![image](https://github.com/lielocks/WIL/assets/107406265/9088bc7f-8cc4-4ea4-9074-a6865714c00d)

<br>

## Thread

### Process 의 한계

과거에는 Program 을 실행할 때 `Process 하나만` 을 사용해서 이용했었다. 

하지만 기술이 발전됨에 따라 Program 이 복잡해지고 다채로워짐으로써 Process 작업 하나만을 사용해서 프로그램을 실행하기에는 한계가 있었다.

오늘날 컴퓨터는 파일을 다운 받으며 다른 일을 하는 Multi 작업은 너무 당연한 기능이라고 생각할지 모르겠지만, 

과거에는 파일을 다운받으면 실행 시작부터 실행 끝까지 Process 하나만을 사용하기 때문에 다운이 완료될때까지 하루종일 기다려야 했다. 

그렇다고 **동일한 Program 을 여러 개의 Process** 로 만들게 되면, 그만큼 `Memory 를 차지하고 CPU 에서 할당받는 자원이 중복` 되게 될 것이다. 

Thread 는 이러한 Process 특성의 한계를 해결하기 위해 탄생 하였다.

<br>

### Thread 의 개념

Thread 란, **하나의 Process 내에서 동시에 진행되는 작업 갈래, 흐름의 단위** 를 말한다.

이해하기 쉽게 비유를 들자면, Chrome 브라우저가 실행되면 Process 하나가 생성될 것이다.

그런데 우리는 브라우저에서 파일을 다운 받으며 온라인 쇼핑을 하며 게임을 하기도 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/ec27a960-0f9e-40b5-877e-093d826852ae)

즉, 하나의 Process 안에서 여러가지 작업들 흐름이 동시에 진행되기 때문에 가능한 것인데, 이러한 일련의 작업 흐름들을 Thread 라고 하며 여러개가 있다면 이를 Multi(다중) Thread 라고 부른다.

아래 그림에서 보듯이 하나의 Process 안에 여러개의 Thread 들이 들어 있다고 보면 된다. 

Thread 수가 많을수록 당연히 Program 속도도 동시에 하는 작업이 많아져 성능이 올라간다.

![image](https://github.com/lielocks/WIL/assets/107406265/f3090831-e52c-4077-bc0e-88bfe7f9b3b7)

일반적으로 하나의 Program 은 하나 이상의 Process 를 가지고 있고, 하나의 Process 는 반드시 하나 이상의 Thread 를 갖는다. 

즉, **Process 를 생성** 하면 기본적으로 **`하나의 main Thread`** 가 생성되게 된다. 

Thread 2개, 3개.. 는 Program 을 개발한 개발자가 직접 프로그래밍하여 위치 시켜주어야 한다. 그래서 별도로 Thread programming 과목이 있는 이유이기도 하다. 

<br>

## Process & Thread 의 Memory

### Process 의 자원 구조

Program 이 실행되어 Process 가 만들어지면 다음 4가지의 Memory 영역으로 구성되어 할당 받게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/44bbaf68-1015-473c-ace7-ba97d085264a)

+ **코드 영역 (Code / Text)** : 프로그래머가 작성한 프로그램 함수들의 코드가 *CPU 가 해석 가능한 기계어 형태* 로 저장되어 있다.

+ **데이터 영역 (Data)** : 코드가 실행되면서 사용하는 전역 변수나 각종 데이터들이 모여있다. .data .rodata .bss 영역으로 세분화된다.
  
  + **`.data`** : *전역 변수* 또는 *static 변수* 등 프로그램이 사용하는 데이터를 저장
 
  + **`.BSS`** : *초기값 없는 전역 변수* , *static 변수* 가 저장
 
  + **`.rodata`** : const 같은 상수 키워드 선언 된 변수나 문자열 상수가 저장

+ **스택 영역 (Stack)** : *지역 변수* 와 같은 호출한 함수가 종료되면 되돌아올 *임시적인 자료* 를 저장하는 독립적인 공간이다.

  Stack 은 함수의 호출과 함께 할당되며, 함수의 호출이 완료되면 소멸한다.

  만일 Stack 영역을 초과하면 stack overflow 에러가 발생한다.

+ **힙 영역 (Heap)** : 생성자, 인스턴스와 같은 *동적* 으로 할당되는 데이터들을 위해 존재하는 공간이다.

  사용자에 의해 Memory 공간이 동적으로 할당되고 해제된다.

<br>

위의 그림에서 Stack 과 Heap 영역이 위아래로 화살표가 쳐 있는 것을 볼 수 있는데, 

이는 **`Code 영역과 Data 영역은 선언할 때 그 크기가 결정되는 Static 영역`** 이지만, 

**`Stack 영역과 Heap 영역은 Process 가 실행되는 동안 크기가 늘어났다 줄어들기도 하는 동적 영역`** 이기 때문에 이를 표현한 것이다.

아래 그림을 보면서 간략히 정리하자면, Program 이 여러개 실행된다면 Memory 에 Process 들이 담길 주소 공간이 생성되게 되고 그 안에 Code, Data, Stack, Heap 공간이 만들어지게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/ccaf3665-9404-4784-b4c2-1075037a27dd)

> **Process vs Thread 주요 차이점**
>
> 동일한 Process 내의 **`Thread`** 는 **공유 Memory** 공간에서 실행되는 반면
>
> **`Process`** 는 **별도의 Memory** 공간에서 실행된다는 점

<br>

### Thread 의 자원 공유

Thread 는 Process 가 할당 받은 자원을 이용하는 실행의 단위로서, Thread 가 여러개 있으면 우리가 파일을 다운 받으며 동시에 웹 서핑을 할 수 있게 해준다. 

Thread 끼리 **Process 의 자원을 공유** 하면서 **Process 실행 흐름의 일부가 되기 때문에 동시 작업** 이 가능한 것이다. 

그래서 아래 사진과 같이 하나의 Process 내에 여러개의 Thread 가 들어있는 상태인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/5edbb9cb-9d13-4e6d-9af6-755886128a32)

이때 Process 의 4가지 메모리 영역(Code, Data, Heap, Stack) 중 Thread 는 **`Stack`** 만 할당받아 **복사** 하고 **`Code, Data, Heap`** 은 Process 내의 다른 Thread 들과 **공유** 된다. 

따라서 각각의 Thread 는 **별도의 Stack** 을 가지고 있지만 **Heap 메모리는 고유** 하기 때문에 서로 다른 Thread 에서 가져와 읽고 쓸 수 있게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/54c75e91-60d0-4f0b-9d39-edd4e46b0703)


> Stack 은 **함수 호출 시** `전달되는 인자`, `되돌아갈 주소 값`, `함수 내에서 선언하는 변수` 등을 저장하는 Memory 공간이기 때문에,
>
> **독립적인 Stack** 을 가졌다는 것은 **독립적인 함수 호출이 가능하다** 라는 의미이다.
>
> 그리고 **독립적인 함수 호출** 이 가능하다는 것은 **독립적인 실행 흐름이 추가된다** 는 말이다.
>
> 즉, ***Stack 을 가짐으로써 Thread 는 독립적인 실행 흐름을 가질 수 있게 되는 것*** 이다.
>
> 반면에 **`Process`** 는 **기본적으로 Process 끼리 다른 Process 의 Memory 에 직접 접근할 수는 없다.**
>

이렇게 구성한 이유는 하나의 Process 를 다수의 실행 단위인 Thread 로 구분하여 자원을 공유하고, 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 올리기 위해서다.

<br>

### Process 의 자원 공유

기본적으로 각 Process 는 Memory 의 별도의 주소 공간에서 실행되기 때문에, **한 Process 는 다른 Process 의 변수나 자료구조에 접근할 수는 없다.** 

_그렇다면 Process 는 영원히 다른 Process 정보에 접근할 수 없을까?_

현재 우리가 사용하는 대부분의 컴퓨터 Program 을 보면 다른 Program 에 있는 정보를 가져오는 경우는 심심치 않게 볼 수 있을 것이다. 

이처럼 특별한 방법을 통해 Process 가 다른 Process 의 정보에 접근하는 것이 가능하다. Process 간 정보를 공유하는 방법에는 다음과 같은 방법들이 있다.

+ **IPC(Inter-Process Communication) 사용**
  
+ **LPC(Local inter-Process Communication) 사용**

+ **별도로 공유 메모리를 만들어서 정보를 주고받도록 설정**

<br>

![image](https://github.com/lielocks/WIL/assets/107406265/d8bf9b6a-b27e-4112-af63-94f553331012)

그러나 `Process 자원 공유` 는 *단순히 CPU Register 교체뿐만이 아니라 RAM 과 CPU 사이의 Cache Memory 까지 초기화*되기 때문에 **자원 부담이 크다는 단점이 있다.**

**그래서 다중 작업이 필요한 경우 Thread 를 이용하는 것이 훨씬 효율적** 이라, 현대 컴퓨터의 OS 에선 다중 Processing 을 지원하고 있지만 `다중 스레싱` 을 기본으로 하고 있다.

<br>

### Thread 장단점

**<장점>**

1. 사용자 응답성 증가

   + Process 가 여러 Thread 로 분할된 경우 일부 Thread 의 처리가 지연되어도, **다른 Thread 는 작업을 계속 처리** 가 가능합니다.

2. 다중 처리로 성능 향상

   + 단일 Process 에 다중 Thread 가 있는 경우 **다중 Process 에서 다중 Thread 를 예약** 할 수 있습니다. 이렇게 하면 Process 성능을 향상할 수 있습니다.
  
3. 경제성이 좋음

   + Thread 는 **한 Process 내에서 자원(code, data, heap) 을 공유** 하기 때문에 Process 에 비해 *자원 할당 비용이 적게 들고* `문맥 교환 (context switch) 비용` 도 적게 듭니다.

4. 통신이 쉬움

   + **`Process`** 간 통신은 `특정 통신 기법 (IPC)` 이 필요하지만, **`Thread`** 는 공유(data, heap) 주소 공간을 사용하면 되기 때문에 `데이터 교환에서는 특별한 기법이 필요 없음.`
     
<br>

**<단점>**

`자원을 공유` 하기 때문에 **타 Thread Memory 공간을 덮어쓸 수 있어서** 안정성에 다소 취약하다.

<br>

## Thread 종류

### 1. 사용자 수준 스레드 User-Level Thread

User Thread 는 `Kernel 영역의 상위` 에서 지원되며 일반적으로 User 수준의 Library 를 통해 구현됩니다.

이 경우 `Kernel` 은 Thread 의 존재를 인식하지 못하기 때문에 ***Kernel 의 개입을 받지 않습니다.***

**`다수의 User-Level Thread`** 가 **`Kernel 수준 Thread 한개에`** mapping 되므로 **다대일(n:1) Thread Mapping** 이라고 합니다.

![image](https://github.com/lielocks/WIL/assets/107406265/c48a815d-9c18-4645-9eeb-294e7860cc91)

**장점**

  + User 영역에서 생성 및 관리되므로 `속도가 빠릅니다.`

  + Kernel 의 개입을 받지 않기 때문에 `이식성(portability) 이 높습니다.` 모든 OS 에서 실행할 수 있음


**단점**

  + Kernel 에서 Thread 가 하나라고 판단하기 때문에 하나의 Thread 가 중단되면 `나머지 모든 Thread 역시 중단` 된다.

<br>

### 커널 수준 스레드 Kernel-Level Thread

Kernel-Level Thread 는 OS 가 지원하는 Thread 기능으로 구현되며, Kernel 이 Thread 생성 및 스케줄링 등을 관리합니다.

User-Level Thread 와 Kernel-Level Thread 가 **일대일 (1:1) 로 Mapping** 됩니다.

따라서 User-Level Thread 를 생성하면 이에 대응하는 Kernel Thread 를 자동으로 생성합니다.

![image](https://github.com/lielocks/WIL/assets/107406265/2f57ccf4-1a97-4e56-a56b-c3fd8f6bf0cf)

**장점**

  + Kernel 이 각 Thread 를 개별적으로 관리하기 때문에 Process 내 Thread 들이 병행으로 수행이 가능합니다.

  + 그렇기 때문에 하나의 Thread 가 중단되어도 다른 Thread 는 계속 수행이 가능합니다.
    

**단점**

  + User Thread 보다 생성 및 관리 속도가 느립니다.

<br>

### 혼합형 Thread

User-Level Thread 와 Kernel-Level Thread 를 혼합한 구조입니다. 이는 User-Level Thread 와 Kernel-Level Thread 의 단점을 극복한 방법입니다.

`User-Level Thread`는 `Kernel-Level Thread 와 비슷한 경량 Process` 에 **다대다로 Mapping** 되고, `경량 프로세스` 는 `Kernel-Level Thread` 와 **일대일로 Mapping** 됩니다.

결국 **`다수의 User-Level Thread 에 다수의 Kernel Thread`** 가 **다대다 (n:m)** 로 mapping 됩니다.

![image](https://github.com/lielocks/WIL/assets/107406265/0c718bdf-a60c-4aaf-b5c5-13d3eeb0289d)

**장점**

  + Process 내 Thread 들이 **병행** 으로 수행이 가능합니다.

  + `Thread Pooling 기법` 을 통해 **`일대일 Thread Mapping`** 에서의 overhead 를 줄여줍니다.
    
<br>

### 스레드 풀링 Thread Pooling

`시스템이 관리하는 Thread 의 Pool` 을 **응용 프로그램에 제공** 하여 Thread 를 효율적으로 사용할 수 있게 하는 방법입니다. 

즉, ***미리 생성한 Thread 를 재사용*** 하도록 하여 `Thread 를 생성하는 시간을 줄여` 시스템의 부담을 덜어줍니다. 

또한 **`동시에 생성할 수 있는 Thread 수를 제한`** 하여 **시스템의 자원 소비를 줄여서** 응용 Program 의 전체 성능을 일정 수준으로 유지합니다.

<br>

## Process & Thread 의 동시 실행 원리

우리가 음악을 들으면서, 웹서핑을 하고, 메신저의 메시지를 확인할 수 있는 이유는 컴퓨터 내부적으로 **Process 와 Thread 를 동시에 처리** 하는 **`Multi Tasking`** 기술 때문이다. 

하지만 여기서 동시에 처리한다는 것이 심플하게 CPU 프로세서가 Program 들을 한꺼번에 동시에 돌리는 것으로 생각하겠지만, 내부적으로 복잡한 원리에 의해 처리가 된다. 

그리고 이 원리가 운영체제 이론의 핵심 원리이기도 하다. 지금부터 그 원리에 대해 파헤쳐 보도록 하자.

![image](https://github.com/lielocks/WIL/assets/107406265/19a038df-a678-442a-8326-cc68e630b0a7)

<br>

### Multi Core 와 Thread

한번 컴퓨터 견적을 맞춰본 경험이 있는 독자분들은 **4 Core 8 Thread** CPU 에 대한 단어를 본 적이 있을 것이다. 

![image](https://github.com/lielocks/WIL/assets/107406265/1ad45abb-a56b-46e2-9add-9c5009068d43)

CPU 한 개는 여러개의 Core 를 가질 수 있다. **Core** 는 말그대로 **CPU core Unit** 으로 CPU 내부에 있는 물리적인 처리회로의 핵심부분이다.

즉, 명령어를 Memory 에서 뽑아 해석하고 실행하는 반도체 Unit 이 4개가 있는 것이다.

`4 Core` 가 **`물리적 Core 갯수`** 면, `8 Thread`는 **`논리적 Core 갯수`** 를 말한다.

이 경우 **물리적 Core 하나가 Thread 두개 이상을 동시에 실행 가능** 하다는 의미가 된다.

즉, OS 가 8개의 작업을 동시에 처리할 수 있다는 뜻이다.

이를 **하이퍼 스레딩 (Hyper-Threading)** 기술이라 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/039f4a59-ab1b-432d-81d3-9409d48a0dfb)


> 단, 여기서 CPU 의 Thread 는 우리가 배운 Process 의 Thread 와는 조금 다른 개념이다.
>
> 엄밀히 말하자면 CPU 의 Thread 는 Hardware 적 Thread 이고 Program 의 Thread 는 Software 적 Thread 로 구분한다.

<br>

그런데 우리는 컴퓨터를 이용할때 Program 을 수십, 수백개를 켜 놓고 이용한다. 그럼 그 수십수백개의 Process 들을 고작 8개의 논리적인 Thread 도 어떻게 처리하는 것일까?

이 원리를 알기위해선 **병렬성(Parallelism)** 과 **동시성(Concurrency)** 이라는 개념을 알고 있어야 한다. 

이 개념은 운영체제의 Process, Thread 를 이해하는데 있어 가장 핵심 골자가 되는 녀석들이다.

<br>

## CPU 의 작업 처리 방식

### 병렬성 (Parallelism)

병렬성은 직관적으로 명령어를 Memory 에서 뽑아 해석하고 실행하는 반도체 Unit 인 여러개의 Core 에 맞춰 여러개의 Process, Thread 를 돌려 병렬로 작업들을 동시 수행하는 것을 말한다.

![image](https://github.com/lielocks/WIL/assets/107406265/bae5eaf5-2504-4d13-a3ab-96e5363e80fc)

Dual Core, Quad Core, Octa Core 등등 이런 명칭이 붙는 Multi Core Processor 가 달린 컴퓨터에서 할 수 있는 방식이다.

![image](https://github.com/lielocks/WIL/assets/107406265/b4d1a62e-a012-466d-a875-1d3c3af6d1d8)

![image](https://github.com/lielocks/WIL/assets/107406265/423af1cc-95d6-4b45-a7df-573f38da345d)

<br>

### 동시성 (Concurrency)

동시성은 **둘 이상의 작업이 동시에 실행되는 것** 을 의미한다. 

이 '동시' 라는 의미에서 병렬성과 동시성의 한글 의미가 헷갈릴수 있다. 

Parallelism 가 물리적으로 정말로 동시에 실행하는 것이라고 하면, Concurrency 는 **동시에 실행하는 것처럼 보이게 하는 것** 으로 이해하면 된다.

즉, 1개의 Core 가 있고 4개의 작업이 있다고 가정하다면, 아래 그림과 같이 Process 들을 ​**계속 번갈아가면서 조금씩 처리함** 으로써 마치 Program 이 **동시에 실행되는 것처럼 보이는 것** 이다. 

이때 Process 들을 ​번갈아가면서 매우 빠르게 처리하기 때문에 컴퓨터를 모르는 사람들이 보면 마치 동시에 돌아가는 것처럼 보이게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/d39ad2c7-52d9-44f2-83ac-26fe437455e4)

단, 이때 작업들을 번갈아가면서 실행할때 작업들을 **아주 잘게 나누어 아주 조금씩만 작업을 수행하고 다음 작업으로 넘어가는 식** 으로 동작된다. 

이렇게 하는 이유는 여러 작업을 동시에 처리하는 것처럼 보이게 만들어, 사용자에게 더 빠른 반응성을 제공하기 위해서다. 

그리고 이렇게 진행 중인 작업들을 A → B → C → D 로 번갈아 바꾸는 것을 **`Context Switching`** 이라고 부른다.

![image](https://github.com/lielocks/WIL/assets/107406265/d1085f86-0024-420c-be24-f4ce0e737f88)

<br>

### 동시성이 필요한 이유

그런데 상식적으로 생각해보면 동시성(Concurrency)은 '동시에 돌아가는 것 처럼' 보이는 거지, 정말 실제로 동시에 돌아가는 것이 아니기 때문에 최종 작업이 걸리는 시간은 거의 차이가 없을 것이다. 

병렬성은 정말로 각 Core 에 Process 를 나눠 실행하는 거니까 Dual Core 면 반 이상 줄어들텐데 말이다. 

*그렇다면 왜 이렇게 번거롭게 작업들을 Switching 하며 처리하는 것일까?*


<br>


첫번째는 **Hardware 적 한계** 때문이라고 할 수 있다. 

CPU 발열 때문에 깡 클럭으로 성능을 올리기에는 한계에 봉착되었기 때문에 Core 의 성능을 올리는 대신 **Core 를 여러개 탑재** 하여 Quad Core, Octa Core CPU 들을 출시하고 있다. 

하지만 아무리 Core 를 많이 넣어도 _수십개의 Core 를 넣을 순 없으니_ 결국 Hardware 적 제한이 걸리게 되고 수십 수백개의 Process 를 돌리기 위해선 결국 **`동시성`** 이 필요한 것이다.


<br>


두번째는 보다 **논리적인 효율적인 이유** 에서이다. 

4 Core 8 Thread 의 CPU 환경에서 현재 총 16개의 작업이 있다고 가정을 해보자. 

그중 8개는 오래 걸리는 작업이고, 나머지 8개는 짧은 시간을 필요로 하는 작업이라고 한다. 

논리적인 8개의 Core 이니 최대 8개까지 동시에 실행할수 있을텐데, 만일 최악의 경우 8개의 오래 걸리는 작업이 먼저 동시에 처리되기 시작했다고 하자. 

이 경우 나머지 가벼운 8개의 작업은 처리하는데 짧은 시간이 걸리는 데에도 불구하고 **현재 처리중인 8개의 작업이 다 끝날때 까지 기다려야 할 것** 이다. 

따라서 이러한 비효율적인 면을 극복하기 위해 **작업을 아주 잘게 나눠 번갈아 가면서 처리하는 `동시성`** 개념을 채택한 것이다.

따라서 최대 8개의 작업에 대해서 8개의 논리적인 Thread 가 병렬적으로 아주 빠르게 동시적으로 작업을 하면서, 그보다 많은 수십개의 Software 적 Thread 가 있다면 적절히 병렬성과 동시성을 섞어 동시에 돌리게 되게 된다.


<br>


## Process & Thread 의 생명 주기

Process 와 Thread 는 각각의 생명 주기를 가지고 있으며, 운영체제는 이러한 생명 주기를 관리하고, Process 와 Thread 를 조정하여 시스템 자원을 효율적으로 사용할 수 있게 된다.


<br>


### Process Scheduling

프로세스 스케줄링(Process Scheduling) 은 *운영체제에서 CPU 를 사용할 수 있는 Process 를 선택*하고, *CPU 를 할당*하는 작업을 말한다. 

Process Scheduling 은 Process 의 우선순위, 작업량 등을 고려하여 효율적으로 배치하여, 이를 통해 운영체제는 CPU 를 효율적으로 사용하며 시스템 전반적인 성능을 향상시킨다. 

그래서 Scheduling 은 Multi Tasking 작업을 만들어내는 데에 있어서 핵심적인 부분이다.

Scheduling 은 운영체제의 특징과 시스템 요구사항에 따라 다양한 알고리즘 방식으로 동작된다. 

알고리즘 종류로는 대표적으로 **FCFS(First-Come, First-Served)** **SJF(Shortest-Job-First)** **Priority** **RR(Round-Robin)** **Multilevel Queue** 등이 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/fa3af473-78e3-44e4-8563-03949945e9c8)

<br>

### Process 상태

Process 의 상태는 Process 가 실행되는 동안 변경되는 고유 상태를 의미한다. 

Process 가 생성되어 실행하기 까지 Process 는 여러가지의 상태를 갖게 되고, 상태의 변화에 따라 Process 가 동작되는 것이다. 

Process 는 일반적으로 다음과 같은 5가지 상태를 가진다.

![image](https://github.com/lielocks/WIL/assets/107406265/7ab59a00-3a20-4915-9b22-00d78e389c6a)

<br>

### Process 상태 전이

Process 상태 전이란 **Process 가 실행되는 동안 상태가 OS 에 의해 변경되는 것** 을 말한다. 

운영체제는 Process 의 상태를 감시하고, Process 상태를 기반으로 Process Scheduling 을 통해 Process 를 관리하고 제어한다. 

예를 들어, `READY 상태에 있는 여러 Process 중` 에서 `어떤 Process 를 RUNNING 상태` 로 바꿀지, `TERMINATED 상태에 있는 Process 를 제거` 하고 `READY 상태에 있는 다른 Process 를 선택할지` Scheduling 알고리즘에 의해 동작된다.

![image](https://github.com/lielocks/WIL/assets/107406265/164e1945-0599-4d90-81dd-5afd70728e91)

1. **Admitted (new -> ready)** : Process 생성을 승인 받음

2. **Dispatch (ready -> running)** : 준비 상태에 있는 여러 Process 들 중 하나가 Scheduler 에 의해 **실행** 됨

3. **Interrupt (running -> ready)** : **Timeout** , 예기치 않은 event 가 발생하여 **현재 실행 중인 Process 를 준비 상태로 전환** 하고, **해당 event 를 먼저 처리**

4. **I/O or event wait (running -> waiting)** : 실행 중인 Process 가 **입출력이나 event 를 처리** 해야 하는 경우, **입출력이나 event 가 끝날때까지 대기 상태** 로 전환

5. **I/O or event completion (waiting -> ready)** : **입출력이나 이벤트가 모두 끝난 Process** 를 **다시 준비 상태** 로 만들어 Scheduler 에 의해 **선택될 수 있는 상태** 로 전환

<br>

### Process Context Switching

Context Switching 은 **`CPU가 한 Process 에서 다른 Process 로 전환할 때 발생하는 일련의 과정`** 을 말한다. 

위의 동시성(Concurrency) 파트에서 다뤘듯이 **CPU 는 한 번에 하나의 Process 만 실행** 할 수 있으므로, ***여러 개의 Process 를 번갈아가며 실행하여 CPU 활용률을 높이기 위해 Context Switching*** 이 필요한 것이다.

Context Switching 을 좀더 구체적으로 말하자면, 

**`동작 중인 Process 가 대기`** 를 하면서 **해당 Process 의 상태(Context)를 보관** 하고, 

**`대기하고 있던 다음 순서의 Process 가 동작`** 하면서 **이전에 보관했던 Process 의 상태를 복구하는 작업** 을 말한다. 

이러한 Context Switching 이 일어날 때 다음번 Process 는 Scheduler 가 결정하게 된다. 

즉, **Context Switching 을 하는 주체** 는 **`Scheduler`** 이다.

![image](https://github.com/lielocks/WIL/assets/107406265/9fb85a4e-a813-44b3-b765-90da3580d5be)


<br>


### PCB (Process Control Block)

PCB(프로세스 제어 블록) 는 운영체제에서 Process 를 관리하기 위해 **해당 Process 의 상태 정보** 를 담고 있는 자료구조를 말한다.

Process 를 Context Switching 할때 `기존 Process 의 상태를 어딘가에 저장` 해 둬야 `다음에 똑같은 작업을 이어서 할 수 있을 것` 이고, `새로 해야 할 작업의 상태` 또한 알아야 `어디서부터 다시 작업을 시작할지` 결정할 수 있을 것이다. 

즉, PCB 는 **Process Scheduling** 을 위해 ***Process 에 관한 모든 정보 저장하는 임시 저장소*** 인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/a5fede1c-69f9-498b-a016-e4318fd0035f)

따라서 운영체제는 **`PCB 에 담긴 Process 고유 정보`** 를 통해 **Process 를 관리** 하며, 

**Process 의 실행 상태** 를 파악하고, **우선순위를 조정** 하며, **Scheduling 을 수행** 하고, **다른 Process 와의 동기화를 제어** 한다.

운영체제에 따라 PCB 에 포함되는 항목이 다를 수 있지만 일반적으로 PCB 내 에는 다음과 같은 정보가 포함되어 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/6797ef2a-f892-41a0-b0a0-8c3b0a52a108)

+ **포인터 (Pointer)** : Process 의 현재 위치를 저장하는 Pointer 정보

+ **프로세스 상태 (Process State)** : Process 의 각 상태 -> 생성(New), 준비(Ready), 실행(Running), 대기(Waiting), 종료(Terminated) 를 저장

+ **프로세스 아이디 (Process ID, PID)** : Process 식별자를 지정하는 고유한 ID

+ **프로그램 카운터 (Program Counter)** : Process 를 위해 **실행될 다음 명령어의 주소를 포함하는 Counter** 를 저장

+ **레지스터 (Register)** : 누산기, 베이스, 레지스터 및 범용 Register 를 포함하는 CPU Register 에 있는 정보

+ **메모리 제한 (Memory Limits)** : 운영 체제에서 사용하는 Memory 관리 시스템에 대한 정보

+ **열린 파일 목록 (List of Open File)** : Process 를 위해 열린 파일 목록


<br>


### Context Switching 과정

두 개의 Process 간에 Context Switching 과정을 그림으로 표현한 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/e60e2f2b-859c-49ee-b019-3cccc047e129)

1. CPU 는 Process P1 을 실행한다. (Executing)

2. 일정 시간이 지나 Interrupt 또는 System Call 이 발생한다. (CPU 는 idle 상태)

3. 현재 실행 중인 Process P1 의 상태를 PCB 1에 저장한다. (Save state into PCB1)

4. 다음으로 실행할 Process P2 를 선택한다. (CPU 스케줄링)

5. Process P2 의 상태를 PCB2 에서 불러온다. (Reload state from PCB2)

6. CPU 는 Process P2 를 실행한다. (Executing)

7. 일정 시간이 지나 Inerrupt 또는 System Call 이 발생한다. (CPU 는 idle 상태)

8. 현재 실행 중인 Process P2 의 상태를 PCB2 에 저장한다. (Save state into PCB2)

9. 다시 Process P1 을 실행할 차례가 된다. (CPU 스케줄링)

10. Process P1 의 상태를 PCB1 에서 불러온다. (Reload state from PCB1)

11. CPU 는 Process P1 을 중간 시점 부터 실행한다. (Executing)

> idle(대기) 와 executing(실행) 은 **CPU 의 동작 상태** 를 나타낸 것이다.


<br>


### Context Switching Overhead

이러한 Context Switching 과정은 사용자로금 빠른 반응성과 동시성을 제공하지만, 실행되는 **Process 의 변경 과정** 에서 `Process 의 상태, Register 값 등이 저장되고 불러오는 등의 작업` 이 수행하기 때문에 _시스템에 많은 부담을 주게된다._

위의 Context Switching 과정 그림을 보면 **`P1 이 Execute 에서 idle 이 될 때`** **`P2 가 바로 Execute 가 되지 않고 idle 상태에 조금 있다가`** **Execute** 가 되는걸 볼 수 있다. 

**이 간극** 이 바로 ***Context Switching Overhead*** 인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/d5d60303-1c2f-4bc3-ae11-827e3314da21)

Context Switching Overhead 는 대표적으로 다음과 같은 행위에 의해서 발생된다.

+ **PCB 저장 및 복원 비용**

+ **CPU Cache Memory 무효화** 에 따른 비용

+ **Process Scheduling** 비용


<br>


Context Switching 과정에서 **PCB 를 저장하고 복원하는데 비용** 이 발생하며, ***Process 자체가 교체되는 것*** 이니 **`CPU 의 Cache Memory 에 저장된 데이터가 무효화`** 가 된다. 

이 과정에서는 **Memory 접근 시간** 이 늘어나고, **성능 저하** 가 발생할 수 있다. 

또한 **CPU Scheduling Algorithm** 에 따라 Process 를 선택하는 비용도 만만치 않다.

바로 뒤에서 다루겠지만, Context Switching 은 꼭 Process 뿐만 아니라 **여러개의 Thread 들끼리도 Switching** 이 일어난다. 

보통 **`Multi Thread`** 라고 하면 여러개의 Thread 가 동시에 돌아가니 Program 성능이 무조건 상승할거라 예상하지만, 이는 정확하지 않다. 

**`Context Switching Overhead`** 라는 변수 때문에 Thread 교체 과정에서 과하게 Overhead 가 발생하면 **오히려 Multi Thread 가 Single Thread 보다 성능이 떨어지는 현상** 이 나타날수 있기 때문이다.


<br>


## Thread Scheduling

Process Scheduling 과 마찬가지로, **`스레드 스케줄링(Thread Scheduling)`** 은 **운영체제에서 다중 Thread 를 관리** 하며, **CPU 를 사용할 수 있는 Thread 를 선택하고, CPU 를 할당하는 작업** 을 말한다.

**`Thread 의 우선순위, 실행 시간, 입출력 요청 등의 정보`** 를 고려하여 **CPU 를 사용할 수 있는 Thread 를 선택하는** Thread Scheduling Algorithm 은 Process Scheduling Algorithm 과 유사하게 동작한다. 

다양한 Algorithm 이 있으며, 대표적으로는 **Round Robin,** **Priority-based scheduling,** **Multi-level Queue scheduling** 등이 있다.

다만 **Thread Scheduling** 은 Process Scheduling 과 다르게, 

*하나의 Process 내에서 다수의 Thread 가 동작* 하는 형태이기 때문에, **Thread 간의 상호작용과 동기화 문제를 고려** 해야 한다는 차이점이 존재한다.

![image](https://github.com/lielocks/WIL/assets/107406265/721e5efa-455f-4b6f-88f2-48e627191074)


<br>


### Thread 상태

Process 상태와 마찬가지로, Thread 에도 상태가 있다. 일반적으로 다음과 같은 4가지 상태를 가진다.

![image](https://github.com/lielocks/WIL/assets/107406265/1a26f6f4-0efd-49d9-9d38-e5f9cfd9abd5)


<br>


### Thread 상태 전이

Thread 상태 전이에 대한 제어는 Java 와 같은 Thread Programming 에서 자세히 다루게 될 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/823d209e-e822-42f4-9762-afe6c54900da)


<br>


## Thread Context Switching

스레드 컨텍스트 스위칭(thread context switching) 은 **`Multi Thread 환경`** 에서 **Thread 간의 실행을 전환** 하는 기술이다. 

Process Context Switching 과 다른점은 Thread Context Switching 은 **하나의 Process 내의 Thread 들을 교환한다** 는 점이다.

![image](https://github.com/lielocks/WIL/assets/107406265/548b3bcc-2761-49de-b34e-a7c21ed903bb)


<br>


### TCB (Thread Control Block)

PCB 처럼, TCB(Thread 제어 블록) 는 **각 Thread 마다 운영 체제에서 유지하는 Thread 에 대한 정보** 를 담고 있는 자료구조이다. 

그림에서 볼 수 있듯이 **`TCB 는 PCB 안에`** 들어있다. 

**Thread 가 Process 내에 위치한 것 처럼 말이다.**

![image](https://github.com/lielocks/WIL/assets/107406265/28ea7fde-f391-417f-9764-8dc36bc845d0)

역시 Thread 의 상태 정보, Thread ID, Thread 우선순위, Scheduling 정보 등 다양한 정보를 저장한다.

TCB 도 Thread 가 생성될 떄 OS 에 의해 생성되며, Thread 가 실행을 마치고 소멸될 때 함께 소멸된다.

또한 **Thread 간의 자원 공유와 동기화** 도 **`TCB`** 를 사용하여 관리된다.

예를 들어 뮤텍스(mutual exclusion) 나 세마포어 (semaphore) 와 같은 동기화 기법을 사용할 때, 

TCB 에서 해당 Thread 의 Mutex 나 Semaphore 정보를 관리하고, ***Thread 가 해당 자원에 대한 접근 권한을 획득하거나 반납할 때*** *TCB 의 정보를 업데이트하게 된다.*

> **Mutex**
> 
> **임계 구역에 1개의 Thread 만** 들어갈 수 있는 동기화 기법
>
> **Semaphore**
> 
> **임계 구역에 여러 Thread** 가 들어갈 수 있고, **`Counter`** 를 두어서 ***허용 가능한 Thread 를 제한*** 하는 기법


<br>


### Process Context Switching vs Thread Context Switching

Process Context Switching 과 Thread Context Switching 은 모두 Multi Tasking 환경에서 여러 Process 또는 Thread 를 동시에 실행하기 위한 기술이다. 그러나 두 기술은 몇 가지 차이점이 있다.
 
**1. TCB 가 PCB 보다 가볍다.**

결론부터 말하자면, Thread Context Switching 이 Process Context Switching 보다 더 빠르다.

위에서 Process 와 Thread 의 Memory 섹션에서 다뤘듯이, Process 내의 Thread 들은 text, data, heap 영역 메모리를 공유하기 때문에 TCB 에는 stack 및 간단한 Register Pointer 정보만을 저장하기 때문에 PCB 보다 TCB 가 가벼워 더 빨리 읽고 쓸 수 있다.

<br>

**2. Cache Memory 초기화 여부**

**CPU Cache Memory** 는 `CPU 와 Main Memory 사이에 위치` 하며 **CPU 에서 한번 이상 읽어들인 Memory 의 데이터를 저장** 하고 있다가, 

_CPU 가 다시 그 Memory 에 저장된 데이터를 요구 할 때,_ **Main Memory 를 통하지 않고 곧바로 데이터를 전달해 주는 용도** 이다.

그런데 **`Process Context Switching`** 이 일어날 경우, ***다른 Process 의 실행*** 으로 인해 **`CPU 가 새로운 명령어와 데이터를 load`** 해야 하기 때문에 **CPU Cache Memory 를 초기화** 하여야 한다. 

이것이 Process Context Switching 에 *부담이 되는 요소이다.*

**`Thread Context Switching`** 일 경우, Process 내 Thread 간에 **Stack 과 Register 값 등 일부 Context 정보만 변경** 되므로 **CPU Cache Memory 는 초기화되지 않는다.** 

다만 *Thread 가 다른 CPU Core 에서 실행될 때는* **해당 Core 의 Cache Memory 에 Thread Context 정보가 load** 되어야 하므로 *초기화될 수 있다.*


<br>


**3. 자원 동기화 문제**

**`Thread Context Switching`** 이 발생해 **다른 Thread 가 heap 영역의 공유 데이터에 접근** 할때, ***이전 Thread 가 이미 공유 자원을 사용하고 있는 경우*** **`동기화 문제`** 가 발생할 수 있다. 

예를 들어, **두 개의 Thread 가 동시에 하나의 변수를 수정** 하려고 할 때, Thread Context Switching 이 발생하면 **변수의 값을 잘못된 값으로 update** 할 수 있는 것이다. 

이것을 Thread 간에 **`경쟁 조건(race condition)`** 이라고 한다.

_Process 는 기본적으로 독립된 공간_ 이지만, IPC 와 같은 **공유 자원** 을 사용하는 경우에 *똑같이 경쟁 조건이 발생할 수가 있다.*

예를 들어, 여러 개의 Process 가 동시에 파일 시스템에 접근하여 파일을 수정하려고 할 때, Context Switching 이 발생할 때 다른 _Process 가 그 파일에 접근할 수 있기 때문에 파일 내용이 손상될 수 있다.

따라서 이들을 해결하기 위해선 각 상황에 적절한 **공유 자원에 대한 동기화 메커니즘** 이 필요해진다.


<br>


# 개요 

+ **Process** 란, 실행 중인 프로그램을 말한다.

+ 우리가 사용하는 컴퓨터에서는 정말 많은 **Process** 들이 실행되고 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/5e26059b-d83d-443a-98c9-fa80dfc6427f)

+ Process 들은 실행을 위해 **CPU, Memory 등의 자원** 들을 **OS** 로부터 할당받아 사용한다.

+ 운영체제가 Process 들에게 효율적으로 자원을 할당하는 것을 **Process Scheduling** 이라고 한다.

<br>

## Program

+ Program 이란, **`명령어들의 집합`** 이다.

+ 여기서 말하는 명령어는 CPU 가 실행하는데 필요한 명령어이다.

+ 즉, 프로그래밍 언어로 작성된 소스 코드를 컴파일하여 만들어진 **명령어들의 집합** 이다.

  + Ex) UNIX 계열 운영체제의 `.out 파일`, Windows 운영체제의 `.exe 파일`

+ Program 은 **보조기억장치** 에 저장되어 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/20730fab-f244-44d9-9676-53acd8339273)

<br>

## Process

+ **Program 이 실행되어 Memory 에 적재된 상태** 를 말한다.

+ **실행 중인 Program** 이라고 볼 수 있다.

  + Ex) 게임 Program(실행파일) 실행 → 게임 Process 생성.

+ Process 생성 시, **OS** 가 Process 에 필요한 **자원을 할당** 한다.

+ 이때, Process 들은 각각의 **독립된 Memory 영역** 을 할당 받는다.

  + 각 Process 들은 자신만의 독립된 Memory 영역을 가지고 있으므로, ***Process 간 통신은 불가능하다.***
 
  + **`Process 간 통신`** 을 위해서는 **`파이프, 시그널, 공유메모리, 파일`** 등을 사용해야 한다.
  
  ![image](https://github.com/lielocks/WIL/assets/107406265/b5074035-3933-48a2-b459-a0198de09dd9)


<br>


## PCB (Process Control Block)

+ **Process 와 관련된 정보**를 저장하는 곳이다.

+ 각 Process 마다 자신만의 PCB 를 가지고 있다.

+ Process ID(PID), Process 상태 등의 정보들을 저장하고 있다.

+ 운영체제는 **PCB 를 통해 각 Process 를 식별** 한다.

+ PCB 는 중요한 정보들을 저장하고 있기 때문에, **Kernel Memory 영역에 저장** 된다.

  + **`Kernel Memory 영역 (OS 영역)`** : **시스템에서 사용해야 하는 필수적인 데이터** 나 중요한 정보들을 저장하기 위해 사용하는 Memory 영역

  + **`User Memory 영역`** : **각 Process 가 할당 받는** Memory 영역 (Code Data Heap Stack)

![image](https://github.com/lielocks/WIL/assets/107406265/3dfbf854-2eff-4c5a-9c20-2ce2da3b429d)

+ **PCB 에 저장되는 정보들** 은 아래와 같다.

  + **Process ID (PID)** : Process 식별 번호
 
  + **Register 값** : Process 가 사용하던 Register 값 (Program Counter 등)
 
  + **Process 상태** : CPU 를 사용 중인 상태인지, CPU 사용을 위해 기다리는 상태인지 등

  + **CPU Scheduling 정보** : 언제, 어떤 순서로 CPU 를 할당 받을지
 
  + **Memory 관리 정보** : Process 가 적재된 Memory 위치
 
  + **사용한 파일 및 입출력 장치 정보** : Process 가 어떤 입출력 장치나 파일을 사용했는지


<br>


## 문맥 교환 Context Switching

+ 모든 Process 들은 실행을 위해 CPU 자원이 필요하지만, **CPU 자원은 한정** 되어 있다.

+ 따라서 **모든 Process 는 동시에 CPU 사용이 불가능** 하며, Process 들은 **차례대로 돌아가면서** 특정 시간 동안 CPU 를 사용한다.

+ 즉 Process 들은 **운영체제가 할당해준 특정 시간만큼 번갈아가면서** CPU 를 사용한다.

+ 이때 실행 중이던 Process 에서 다른 Process 로 실행 순서가 넘어갈 때, 운영체제는 **현재까지 실행 중이던 Process 의 정보를 PCB 에 저장하고**,

  **다음에 실행할 Process 의 정보를 해당 Process 의 PCB 로부터 불러온다.**

+ 이 과정을 **문맥 교환**이라고 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/74122b47-4234-4e2a-99bc-3b95de2d6b97)

+ 문맥 교환은 **아주 빠르게 수행** 되기 때문에 (현대 시스템에서는 수십 usec 정도), 사용자 입장에서는 여러개의 Process 가 **동시에 실행되고 있는 것처럼 보인다.**

+ 문맥 교환이 자주 일어나게 된다면, 그만큼 **overhead** 가 발생할 수 있다.

  + overhead : 특정 기능을 수행하는데 추가적으로 시간, 자원이 소모되는 것

<br>

## 프로세스 상태 Process Status

+ Process 가 실행될 때, 각 Process 는 **여러 가지의 상태를 거치며 실행**된다.

![image](https://github.com/lielocks/WIL/assets/107406265/8680f95f-e617-43b7-a0b6-476dd41b60e8)
  
  1. 생성 상태 (NEW) : Process 가 이제 막 **Memory 에 적재되어 PCB 를 할당 받은 상태**
 
  2. 준비 상태 (READY) : CPU 를 할당 받으면 실행이 가능하지만, 자신의 **차례를 기다리는 상태**
 
  3. 실행 상태 (RUNNING) : CPU 를 할당 받아 **실행 중인 상태**

     + **일정 시간 동안** 만 CPU 사용이 가능하다.
    
     + 할당된 시간을 모두 사용하면 **Timer Interrupt** 가 발생하며 다시 준비 상태로 변경된다.

  5. 대기 상태 (WAITING) : 입출력 요청을 받게 되어 입출력 작업을 완료할 때까지 **대기하는 상태**

     + 입출력 작업이 끝나고 **입출력 완료 Interrupt** 를 받을 때까지 대기하는 상태이다.
    
     + 정확히는 **특정 event 가 일어나기까지 기다리는 것** 이며, 대부분의 이벤트가 `입출력 작업`이다.
    
  7. 종료 상태 (END) : Process 가 종료된 상태


<br>


## 프로세스 스케줄링 Process Scheduling

+ 운영체제가 **Process 들에게 공정하고 합리적으로 자원을 배분하는 것** 을 말한다.

+ 특정 자원의 할당을 원하는 Process 들은 해당 자원의 **Scheduling Queue** 에서 대기한다.

  + 대표적인 Scheduling Queue 에는 **준비 Queue** 와 **대기 Queue** 가 있다.

    + **`준비 Queue`** : **CPU 사용** 을 위해 기다리는 Queue

    + **`대기 Queue`** : **입출력 장치 사용** 을 위해 기다리는 Queue
      
![image](https://github.com/lielocks/WIL/assets/107406265/9d125542-cffd-4efd-8e5d-ef23e200fc34)
  
  + Scheduling Queue 는 반드시 선입선출(FIFO) 방식은 아니며, **Process 들이 대기하는 공간** 일 뿐이다.

+ 운영체제는 Scheduling Queue 에서 대기하는 각 Process 들의 **우선순위** 를 고려하여 자원을 배분한다.

![image](https://github.com/lielocks/WIL/assets/107406265/4ad092a6-9381-426f-9e4d-37b2898a759b)
![image](https://github.com/lielocks/WIL/assets/107406265/73c23f91-4d90-4f6b-9e6e-5a4224cccfb0)
![image](https://github.com/lielocks/WIL/assets/107406265/5c8520c3-ccb5-45cf-ae4a-4820006045ae)


<br>


## 프로세스 스케줄링 알고리즘 Process Scheduling Algorithm

+ 운영체제가 **Process Scheduling 을 위해 사용하는 실질적인 방법**이다.

+ 대표적인 CPU 할당을 위한 Process Scheduling Algorithm 의 종류는 아래와 같다.


1. **선입 선처리 Scheduling**
     
     + 준비 Queue 에 삽입된 순서대로 CPU 를 할당해주는 방식이다.
    
     + 먼저 실행되는 Process 들의 실행 시간이 길다면, 대기 중인 Process 들이 기다리는 시간이 매우 길어질 수 있다.

<br>

2. **최단 작업 우선 Scheduling**

     + 실행 시간이 가장 짧은 Process 부터 CPU 를 할당해주는 방식이다.

<br>

3. **라운드 로빈 Scheduling**

     + **준비 Queue 에 삽입된 순서대로 CPU 를 할당** 하지만, **정해진 시간(Time Slice) 만큼만 할당** 해주는 방식이다.
    
     + 정해진 시간동안 전부 실행되지 못했다면, 맨 마지막 순서로 돌아가서 다시 기다린다.
     
     ![image](https://github.com/lielocks/WIL/assets/107406265/1320eafb-d99e-40ae-8d0c-b161e323c0a0)


<br>

4. **최소 잔여 시간 우선 Scheduling**

    + 정해진 시간만큼 CPU 를 할당하되, 다음 Process 는 *남은 작업 시간이 가장 적은 Process* 를 선택하는 방식이다.

<br>

5. **우선순위 Scheduling**

     + Process 들에 우선순위를 부여하고, 우선순위가 높은 Process 부터 실행시키는 방식이다.
    
     + 우선순위가 같다면, `선입 선처리`로 처리한다.
    
     + 우선순위가 낮은 Process 는 무한정 실행되지 못하는 **기아(Starvation) 현상** 이 발생한다.
    
     + 기아 현상 방지를 위해 오래 기다린 Process 의 우선순위를 점차 높이는 **에이징(Aging)** 기법을 사용한다.

<br>

6. **다단계 큐 스케줄링 Multi-level Queue Scheduling**

     + 우선순위별로 준비 Queue 를 여러개 사용하는 Scheduling 방식이다.
    
     + 우선순위가 가장 높은 Queue 에 있는 Process 를 먼저 처리한다.
    
     + 우선순위가 가장 높은 Queue 가 비어 있으면, 그 다음 우선순위 Queue 를 처리한다.
    
     + 우선 순위가 낮은 Process 는 기아 현상이 발생할 수 있다.

     ![image](https://github.com/lielocks/WIL/assets/107406265/1dfd987d-875e-431b-9a10-b657320030f2)

<br>

7. **다단계 피드백 Queue Scheduling**

     + **Queue 간의 이동** 이 가능한 다단계 Queue Scheduling 이다.
    
     + **우선순위** 가 가장 높은 Queue 부터 처리를 하되, 일정 시간(Time Slice) 동안 못 끝낸 경우 **그 다음 우선 순위 Queue** 로 다시 이동하여 대기한다.
    
     + _CPU 사용 시간이 길수록_ 우선 순위가 내려가게 된다.
    
     + 즉, CPU 사용 시간이 긴 **`CPU 집중(CPU Bound) Process`** 는 우선 순위가 상대적으로 **낮아지고,**

       CPU 사용 시간이 짧고 입출력 작업이 많은 **`입출력 집중(I/O Bound) Process`** 는 우선 순위가 상대적으로 **높아진다.**

       ![image](https://github.com/lielocks/WIL/assets/107406265/f30e7a9a-a9b1-49d1-88c9-22243da2b522)

     + 또한, **에이징** 기법을 통해 기아 현상을 방지한다.

       ![image](https://github.com/lielocks/WIL/assets/107406265/d49893bf-581e-4d89-8797-5a0282942ddc)

       ![image](https://github.com/lielocks/WIL/assets/107406265/ee68b22d-46b9-442a-adfd-c546f017464d)

<br>

# Multi Process vs Multi Thread

Multi Process 와 Multi Thread 는 **한 어플리케이션에 대한 처리방식** 이라고 보면 된다.

단순히 Program 을 여러개 띄워놓는 것이 Multi Process 가 아니라 이 둘은 언제 어느때에 어떤 방식으로 처리하느냐에 따라 다른 것으로 이해해야 한다.

이름으로 유추할 수 있듯이 Multi Process 와 Multi Thread 는 여러개의 Process, Thread 가 동작하는 것을 일컫는다.

단일이 아닌 다중으로 돌아감으로써 성능 향상 등 여러가지 효과를 얻을 수 있다. 

하지만 또한 이로 인해 발생되는 부가적인 문제점도 발생하게 된다. 지금 부터 이에 대해 자세히 알아보자

![image](https://github.com/lielocks/WIL/assets/107406265/861c644a-3844-4a83-8265-bc4c7c403044)

<br>

## Multi Process

Multi Process 는 운영체제에서 하나의 응용 Program 에 대해 동시에 여러 개의 Process 를 실행할 수 있게 하는 기술을 말한다. 

보통 하나의 Program 실행에 대해 하나의 Process 가 Memory 에 생성되지만, 부가적인 기능을 위해 여러개의 Process 를 생성하는 것이다.


> **Multi Process vs Multi Processor**
>
> **`프로세스(process)`** 는 **프로그램의 실행 상태**를 말하고, **`프로세서(processor)`** 는 **CPU 코어**를 일컫는다.
>
> 둘이 단어가 유사해서 굉장히 혼동할 수 있을텐데, 어쨋든 둘이 의미하는 바는 완전히 다르다고 보면 된다.
>
> 따라서 **`Multi Process`** 는 하나의 Program 에서 여러 개의 Process 를 실행하는 것을 의미하고, **`Multi Processor`** 는 여러 개의 CPU Core 가 하나의 시스템에서 동시에 실행되는 것을 의미한다.

<br>

Multi Process 내부를 보면, 하나의 부모 Process 가 여러 개의 자식 Process 를 생성함으로서 다중 Process 를 구성하는 구조이다. 

한 Process 는 실행되는 도중 Process 생성 System Call 을 통해 새로운 Process 들을 생성할 수 있는데,

`다른 Process 를 생성하는 Process`를 **부모 프로세스(Parent Process)** 라 하고, `다른 Process 에 의해 생성된 Process`를 **자식 프로세스(Child Process)** 라 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/b2669f92-5842-4dfa-914b-8a29b238bca5)

부모 Process 와 자식 Process 는 **`각각 고유한 PID(Process ID)`** 를 가지고 있다. 

부모 Process 는 자식 Process 의 PID 를 알고 있으며, 이를 통해 자식 Process 를 제어할 수 있다. 

또한, 자식 Process 는 부모 Process 의 PID 와 PPID(Parent Process ID) 를 알고 있어, 이를 통해 부모 Process 와의 통신이 가능하다.

다만, 통신이 가능할 뿐이지, 부모 Process 와 자식 Process 는 엄연히 서로 다른 Process 로 **독립적으로 실행** 되며, **`독립적인 Memory 공간`** 을 가지고 있어 서로 다른 작업을 수행한다. 

대표적인 예로 웹 브라우저의 상단 탭(Tab) 이나 새 창을 들 수 있다. 

각 브라우저 탭은 `같은 브라우저 Program 실행`이지만, `각기 다른 사이트 실행`을 행하기 때문이다.

![image](https://github.com/lielocks/WIL/assets/107406265/f6ecb5f1-bf4a-4555-bcdd-c4a18ba3d33c)

이러한 브라우저 Multi Process 원리를 확인하기 위한 간단한 실험도 가능하다. 

여러개의 탭을 띄운뒤, 하나의 탭에서 F12로 개발자 도구를 열고 콘솔 탭에 `while(1) {}` 무한 루프 코드를 실행 시켜보자. 

그러면 `해당 탭에서는 클릭도 안되고 먹통이 되는 현상` 을 경험할 수 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/0f6f0ea6-6c06-46a2-86e3-c0edf1615d0a)

하지만 다른 탭에는 정상적으로 브라우징이 가능하다. 

이는 **Tab 마다 다른 Process 로 동작** 하기 때문이다.

<br>

## Multi Process의 장점

**1. Program 안전성**

Multi Process 는 **각 Process 가 독립적인 Memory 공간** 을 가지므로, ***한 Process 가 비정상적으로 종료되어도 다른 Process 에 영향을 주지 않는다.*** 

그래서 `Program 전체의 안전성을 확보`할 수 있다는 장점이 있다.

예를 들자면 크롬 브라우저에서 여러개의 탭을 띄우고 여러곳의 웹사이트를 방문해 서비스를 이용한다고 하자. 

이때 어느 한 탭의 웹사이트에서 무언가 잘못되어 먹통이 되었다. 

![image](https://github.com/lielocks/WIL/assets/107406265/3af9422f-8bab-4ad2-835b-a9b15dffb3c5)

아주 심각한 오류가 아닌 이상, 당장 그 브라우저 탭의 웹사이트는 이용을 못하겠지만, 다른 탭은 별 문제없이 이용이 가능할 것이다. 

이러한 이유는 **자식 Process 가 여러개** 생성되어 **Memory 에 별도로 관리** 되기 때문이다.

![image](https://github.com/lielocks/WIL/assets/107406265/04cb9b99-3bba-451c-a3b5-fbb712de53ba)

<br>

**2. Program 병렬성**

Multi Process 와 여러개의 CPU 코어를 활용하여 둘의 시너지를 합쳐, ***다중 CPU 시스템*** 에서 **각 Process 를 병렬적으로 실행하여 성능을 향상** 시킬 수 있다. 

예를 들어 `Image 처리나 Video Encoding`과 같은 작업을 **여러 개의 Core 나 CPU 에 분산시켜 빠르게 처리** 할 수 있다.

다만, 이 부분은 Multi Process 만의 장점이라기 보단, **Multi Process 와 Multi Thread 둘의 장점** 이 옳다. 

그리고 **`Multi Thread`** 로 구성하는 것이 Multi Process 로 구성하는 것보다 **훨씬 효율적이고 빠르기 때문에,** Multi Process 로 성능을 올리는 행위는 거의 없다고 보면 된다. 

이에 대해선 뒤의 Multi Thread 파트에서 다시 다룬다.

![image](https://github.com/lielocks/WIL/assets/107406265/e1cd5a91-1830-4c71-9797-eb1c8b99bc83)

<br>

**3. 시스템 확장성**

Multi Process 는 **각 Process 가 독립적** 이므로, `새로운 기능이나 모듈을 추가하거나 수정`할때 다른 Process 에 **`영향을 주지 않는다.`** 

그래서 **시스템의 규모를 쉽게 확장** 할 수 있다.

이 부분에 대해서는 컴퓨터의 소프트웨어로 예시를 드는 것보다 네트워크의 서버(server)로 드는 것이 적절하기 때문에 잠시 `분산 서버`에 대해서 말해보겠다. 

대규모 웹 서비스에서는 `수많은 요청을 동시에 처리`하기 위해 여러대의 서버를 두고 **로드 밸런서(Load Balancer)** 와 같은 장비를 사용하여 ***Client 요청 트래픽을 분산 시킨다.*** 

이때 여러대의 서버는 `컴퓨터를 여러개`를 말하는 것일 수도 있고, `하나의 성능 좋은 컴퓨터에 여러개의 서버 Process`를 두는 것을 말하기도 한다. 

Multi Process 의 상황은 후자이다.

서버 프로그래밍을 해본 백엔드 개발자분들은 **서버 클러스터(cluster)** 를 구성해본 적이 있을 것이다. 

**`하나의 컴퓨터에 여러개의 서버 Process`** 를 띄움으로써 **요청을 분산** 시키는 것이다. Node.js 진영에선 대표적으로 PM2 가 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/7f5caf61-898b-4cc1-a3fb-008e347d78df)

이렇게 Multi Process 를 사용하여 여러 대의 서버에 요청을 분산시켜 처리함으로써, 시스템의 규모를 쉽게 확장할 수 있으며, 부가로 서버의 장애나 다운타임을 최소화할 수 있게 되는 것이다.

<br>

## Multi Process 의 단점

### 1. Context Switching Overhead

멀티 태스킹(multi tasking)을 구성하는데 핵심 기술인 **컨텍스트 스위칭(context switching)** 과정에서 `성능 저하`가 올 수 있다. 

특히나 Process 를 Context Switching 하면, 

CPU 는 **`다음 Process 의 정보를 불러오기 위해 Memory 를 검색`**하고, **`CPU Cache Memory 를 초기화`**하며, **`Process 상태를 저장`**하고, **`불러올 데이터를 준비`** 해야 하기 때문에, 이로 인한 빈번한 Context Switching 작업으로 인해 비용 **`Overhead 가 발생`** 할 수 있게 된다. 

반면 Thread 를 Context Switching 하면 Process Switching 보다 가벼워 훨씬 빠르고 좋다.

![image](https://github.com/lielocks/WIL/assets/107406265/5fe340cf-c664-4ae2-900a-8e90d2a31c9e)

따라서, Multi Process 환경에서는 Context Switching Overhead 를 최소화하는 방법이 중요하다. 

이를 위해서 

+ Process 수를 적정하게 유지하거나,

+ **I/O Bound 작업** 이 많은 Process 와 **CPU Bound 작업** 이 많은 Process 를 분리하여 관리하고,

+ **CPU Cache 를 효율적으로 활용** 하는 등의 방법을 고려해 봐야 한다.

<br>

### 2. 자원 공유 비효율성

Multi Process 는 각 Process 가 **독립적인 Memory 공간** 을 가지므로, **`결과적으로 Memory 사용량이 증가`** 하게 된다.

만일 **`각 Process 간에 자원 공유`** 가 필요할 경우 Process 사이의 어렵고 복잡한 통신 기법인 **IPC(Inter-Process Commnuication)** 을 사용하여야 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/04ccd3fe-9d2f-470f-945c-13acac98e648)

IPC 란 **운영체제 상에서 실행 중인 Process 간에 정보를 주고받는 메커니즘** 을 말한다. 

이를 위해 `파이프, 소켓, 메세지 큐` 등 다양한 방법이 사용된다. 

그런데 **`IPC 자체로 Overhead 가 발생`** 한다. 

예를 들어, `파이프나 소켓과 같은 IPC 기법`은 *데이터를 복사* 하거나 *버퍼링하는 과정* 에서 **성능 저하** 가 발생할 수 있기 때문이다. 또한 코드의 복잡도를 증가시킨다.

<br>

## Multi Thread

Thread 는 **하나의 Process 내** 에 있는 `실행 흐름`이다. 

그리고 Multi Thread 는 **하나의 Process 안에 여러개의 Thread** 가 있는 것을 말한다. 

따라서 `하나의 Program` 에서 `두가지 이상의 동작을 동시에` 처리하도록 하는 행위가 가능해진다.

**Web Server** 는 대표적인 Multi Thread 응용 프로그램이다.

사용자가 `Server DB 에 자료를 요청하는 동안` ***브라우저의 다른 기능을 이용*** 할 수 있는 이유도 바로 Multi Thread 기능 덕분인 것이다. 

즉, **`하나의 Thread 가 지연`** 되더라도, **다른 Thread 는 작업을 지속** 할 수 있게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/bdbfd1c7-fc8d-4536-ac6d-6ea31f31f380)

Multi Process 와의 차이점을 부각시키기 위해, Multi Process 를 설명할때 예시를 들었던 웹 브라우저를 다시 들어보겠다. 

**`Multi Process`** 는 웹 브라우저에서의 **여러 탭이나 여러 창** 이라고 말했었다. 

대신 **`Multi Thread`** 는 웹 브라우저의 **단일 탭** 또는 **창 내에서 브라우저 이벤트 루프, 네트워크 처리, I/O 및 기타 작업을 관리하고 처리** 하는데 사용된다고 보면된다.

<br>

## Multi Thread 의 장점

윈도우, 리눅스 등 많은 운영체제들이 멀티 프로세싱을 지원하고 있지만 멀티 스레딩을 기본으로 하고 있다.

**왜 Multi Process 보다 `Multi Thread` 로 프로그램을 돌리는 것이 유리한지** 그 이유에 대해 알아보자.

(이는 Thread 자체의 장점)

<br>

### 1. Thread 는 Process 보다 가벼움

일단 Thread 는 Process 보다 **용량이 가볍다.**

그도 그럴게 Thread 는 **Process 내에서 생성**되기 때문에 ***Thread 의 실행 환경을 설정하는 작업이 매우 간단*** 하여 `생성 및 종료가 빠르다.`

또한 Thread 는 Process 와 달리, **`Code, Data, Stack 영역을 제외한 나머지 자원`** 을 **서로 공유** 하기 때문에 `기본적으로 내장되어 있는 데이터 용량`이 Process 보다 당연히 작다. 

그래서 **`Thread 를 생성하고 제거할 때,`** **Process 내부의 자원만을 관리** 하면 되기 때문에 Process 생성, 제거 보다 **훨씬 빠른 것** 이다.


<br>


### 2. 자원의 효율성

Multi Thread 는 하나의 Process 내에서 여러 개의 Thread 를 생성되기 때문에, **heap 영역과 같은 공유 Memory** 에 대해 **`Thread 간에 자원을 공유`** 가 가능하다. 

이를 통해, **`프로세스 간 통신(IPC) 을 사용하지 않고`** **데이터를 공유** 할 수 있기 때문에, 자원의 효율적인 활용이 가능해 시스템 자원 소모가 줄어든다.

![image](https://github.com/lielocks/WIL/assets/107406265/f837f733-6fb6-403b-951e-2e588bb9de69)

<br>

### 3. Context Switching 비용 감소

Thread 에도 Context Switching Overhead 가 존재한다.
하지만 상대적으로 Process Context Switching Overhead 보다 훨씬 낮아 비용이 낮다는 장점이 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/0a09d578-8499-47be-8188-0f783176757b)

**`Process Context Switching 비용`** 은 Switching 할 때마다 ***CPU Cache 에 있는 내용을 모두 초기화*** 하고, ***새로운 Process 정보를 CPU Cache 에 적재*** 해야 하므로 `높은 비용`이 든다. 

반면, **`Thread Context Switching 비용`** 은 Switching 할 때 Thread 간에 공유하는 자원을 제외한 **Thread 정보(Stack, Register) 만을 교체** 하면 되므로 Process Context Switching 비용보다 상대적으로 낮은 것이다.


> **[ Context Switching 이 빨라진 Thread 와 Cache 적중 ]**
>
> Thread 는 **공유하는 영역이 많기 때문에** Context Switching 이 **`빠르다`**
>
> Cache 는 CPU 와 Main Memory 사이에 위치하며 CPU 에서 한번 이상 읽어들인 Memory 의 데이터를 저장하고 있다가, CPU 가 다시 그 Memory 에 저장된 데이터를 요구할 때, Main Memory 를 통하지 않고 데이터를 전달해주는 용도이다.
>
> ***Process Context Switching 이 일어났을 경우, 공유하는 데이터가 없으므로 Cache 가 지금껏 쌓아놓은 데이터들이 무너지고 새로 Cache 정보를 쌓아야 한다.***
>
> 이것이 **Process Context Switching 에 부담이 되는 요소이다.**
>
> 반면, Thread 라면 저장된 Cache 데이터는 Thread 가 바뀌어도 공유하는 데이터가 있으므로 의미있다.
>
> 그러므로 **Thread Context Switching 이 빠른 것** 이다.

<br>

### 4. 응답 시간 단축

앞의 Multi Thread 의 장점을 종합해보자면, Multi Thread 는 **Thread 간의 통신이나 자원 공유**가 더욱 용이하며, Process 보다 **가벼워 Context Switching Overhead 도 작다.** 

따라서 멀티 프로세스 보다 ***응답 시간이 빠르다.***

예를 들어, Web Server 에서 Client 요청을 처리하는 경우, 

**`Multi Process 방식`** 에서는 각 요청마다 Process 를 생성하여 처리해야 하므로, Overhead 가 크지만, **`Multi Thread 방식`** 에서는 **여러 개의 Thread 가 하나의 Process 내에서 요청을 처리** 할 수 있으므로, **Overhead 가 감소해 더욱 빠른 응답 시간** 을 보장할 수 있는 것이다.

이러한 이유로, `Multi Processor 환경`에서 `Multi Thread` 를 사용하여 작업을 처리하는 것이 `Multi Process` 를 사용하는 것보다 더 효율적이다라고 말할 수 있다.


<br>


## Multi Thread 의 단점

### 1. 안정성 문제

Multi Process 모델에서는 각 Process 가 독립적으로 동작하므로 하나의 Process 에서 문제가 발생해도 다른 Process 들은 영향을 받지 않기 때문에 Program 이 죽지 않고 계속 동작할 수 있다. 

그러나 Multi Thread 모델에서는 ***기본적으로 하나의 Thread 에서 문제가 발생하면*** 다른 Thread 들도 영향을 받아 **전체 Program 이 종료** 될 수 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/eb68ee60-589b-4df7-8f94-aa6af317028b)

물론 이는 프로그래머의 역량에 따라 극복할 수 가 있다. 

예를 들어 Thread 에 에러가 발생할 경우 이에 대한 `적절한 예외 처리`를 잘 해놓는다던지, 에러 발생 시 `새로운 Thread 를 생성`하거나 `스레드 풀(Thread Pool)에서 잔여 Thread` 를 가져오던지 하여 **Program 종료를 방지** 할 수 있다. 

다만, 이때 **새로운 Thread 생성** 이나 **놀고 있는 Thread 처리** 에 `추가 비용`이 발생하게 된다.

<br>

### 2. 동기화로 인한 성능 저하

Multi Thread 모델은 **여러 개의 Thread 가 공유 자원에 동시에 접근** 할 수 있기 때문에, **`동기화 문제`** 가 발생할 수 있다. 

예를들어 `여러 Thread 가 동시에 한 자원을 변경` 해 버린다면 **의도되지 않은 엉뚱한 값** 을 읽어 `서비스에 치명적인 버그`가 생길수도 있다. 

따라서 **Thread 간 동기화(syncronized)** 는 **데이터 접근을 제어** 하기 위한 필수적인 기술이다. 

동기화 작업은 **`여러 Thread 들이 자원에 대한 접근`** 을 **순차적으로 통제** 하는 것이다. 

그러면 동시 접근으로 인한 동시 수정과 같은 현상은 일어나지 않게 된다. 

그러나 동기화 작업은  ***여러 Thread 접근을 제한***하는 것이기 때문에 **`병목 현상`** 이 일어나 *성능이 저하될 가능성이 높다는 단점이 있다.*

![image](https://github.com/lielocks/WIL/assets/107406265/a4b927f7-a030-4b62-891c-d029aaa0abea)

이를 해결하기 위해 임계 영역(Critical Section)에 대하여 뮤텍스(mutex), 또는 세마포어(Semaphore) 방식을 활용한다.


> **임계 영역 Critical Section**
> - Multi Thread 프로그래밍에서 임계 영역은 **공유 자원을 접근하는 코드 영역** 을 말한다. 대표적으로 _전역 변수나 heap 메모리 영역_ 을 들 수 있겠다.
>
> **뮤텍스 Mutex**
> 
> - 공유 자원에 대한 **접근을 제어하기 위한 상호 배제 기법** 중 하나
> - 임계 영역에 진입하기 전에 **lock 을 획득** 하고, 임계 영역을 빠져나올 때 **lock 을 해제** 하여 다른 Thread 들이 접근할 수 있도록 한다.
> - 한마디로 **`오직 1개의 Thread 만이 공유 자원에 접근`** 할 수 있도록 제어하는 기법이다.
>
> **세마포어 Semaphore**
> 
> - 세마포어는 **동시에 접근 가능한 Thread 의 개수를 지정** 할 수 있다.
> - **`Semaphore 값이 1`** 이면 **Mutex 와 동일한 역할** 을 하며, **`값이 2 이상`** 이면 **동시에 접근 가능한 Thread 의 수를 제어** 할 수 있다.
> - Thread 가 *임계 영역에 진입하기 전* 에 **Semaphore 값을 확인** 하고, ***값이 허용된 범위 내에 있을때만 lock 을 획득*** 할 수 있는 형식이다. 한마디로 Mutex 상위 호환이라고 보면 된다.

<br>

### 3. Deadlock (교착 상태)

Deadlock 이란, `다수의 Process 나 Thread` 가 **서로 자원을 점유** 하고, `다른 Process 나 Thread 가 점유한 자원을 기다리는 상황` 에서 발생하는 **교착 상태** 를 말한다. 

여러 개의 Thread 가 서로 대기하면서 무한정 기다리게되는 **무한 루프** 와 같은 증상이라고 보면된다.

예를들어, **`Thread 1 은 자원 A을 점유하고 있는 상태에서 자원 B가 필요`** 한 상황이다. 

그리고 **`Thread 2 는 자원 B를 점유하고 있는 상태에서 자원 A이 필요한 상황`** 이다. 

하지만 **Thread 1은 자원 B가 필요한 상황에서 자원 A을 빌려줄 수 있는 상황이 아니고, Thread 2 또한 자원 A 이 필요한 상태에서 자원 B 를 빌려줄 수 없는 상황** 인 것이다.

이처럼 다수의 Thread 가 **같은 lock** 을 동시에, ***다른 명령에 의해 획득하려 할 때 서로 절대 불가능한 일을 계속적으로 기다리는 상황*** 을 이야기 한다. 

![image](https://github.com/lielocks/WIL/assets/107406265/5acf5380-ed6e-469c-af62-41a78a38b0d6)

이러한 현상은 Thread 의 특징인 **공유 자원에 대한 동시 엑세스** 로 인한 문제로, 

이를 방지하기 위한 상호배제(Mutual Exclusion), 점유와 대기(Hold and Wait), 비선점(No Preemption), 순환 대기(Circular Wait) 등의 알고리즘을 통해 극복해야 한다.

다만, Deadlock 은 Multi Thread 만의 단점이라기 보다는 **Multi Process 와 Thread 모델의 공통된 문제점** 이라고 말하는 것이 옳다. 

왜냐하면 **Process 끼리는 기본적으로 독립적인 Memory 공간** 이지만 **`IPC 를 통해 공유 자원을 사용`** 할 수 있기 때문에 ***Multi Thread 와 똑같이 교착 상태*** 에 빠질 수 있기 때문이다.

<br>

### 4. 그래도 Context Switching Overhead

앞서 Multi Process 보다 Multi Thread 의 Context Switching Overhead 가 작아 성능에 유리하다라고 설명했었지만, **그래도 Context Switching Overhead 비용** 자체를 무시할수는 없다. 

특히나 **`Thread 수가 많으면 많을수록 그만큼 Context Switching 이 많이 발생`** 되게 되고 당연히 이는 **성능 저하**로 이어진다.

이 부분은 'Thread 를 많이 쓸수록 항상 성능이 좋아질까?' 라는 물음으로 던질 수 있다. 

보통 사람들이 생각하기에는 Thread 가 많으면 많을 수록 그만큼 동시 처리수가 늘어나 당연히 Thread 가 많으면 무조건 좋다고 이야기할 것이다. 

하지만 'Context Switching Overhead' 라는 개념을 알고 있는 개발자인 우리들은 '과연 꼭 그럴까?' 라는 의문을 던져야 한다.

<br>

### 5. 디버깅이 어려움

Multi Thread 를 사용하면, **여러 개의 Thread 가 동시에 실행** 되기 때문에, **각 Thread 의 동작을 추적하기 어려울 수 있다.** 

예를 들어 코드를 디버깅하는 도중에 `다른 Thread 가 실행되어 예기치 않은 결과`가 발생할 수 있다. 

또한 **어떤 Thread 가 언제 어떤 자원에 접근**하고, **어떤 순서로 실행되는지** 등을 파악하기 어려울 수 있다.

따라서 Thread 간의 상호작용과 동기화 기법을 잘 이해하고, 디버깅 도구를 적극적으로 활용해야 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/a0632afe-21d4-427f-a633-757a692d97a5)

<br>

### 6. 운영체제의 지원이 필요

오늘날의 윈도우, 리눅스, 맥 OS 에선 모두 기본적으로 멀티 스레딩을 기본적으로 지원하도록 설계 되었으니 문제점이라기에는 약간 어폐가 있긴 하다. 

하지만, 1980년대의 SunOS3와 같은 오래된 유닉스 시스템에는 Thread 가 없었고 Process 만 있는, 멀티 스레딩을 지원하지 않는 운영 체제가 있었기 때문에 Multi Thread 의 단점으로 넣어 보았다. (생략해도 상관 없다.)


