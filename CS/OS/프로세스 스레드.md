# 프로세스 & 스레드 개념
![image](https://github.com/lielocks/WIL/assets/107406265/20a7d582-c988-4a20-95fb-df1b90f02b7f)

일단 프로세스의 **작업의 단위** 라는 단어와 스레드의 **실행 흐름의 단위** 라는 단어를 기억해 두고 글을 읽어보자.

<br>

## 프로그램과 프로세스

### 정적 프로그램 (Static Program)
컴퓨터 전공이 아니라서 '프로세스' 라는 명칭은 낯설수 있는데, '프로그램' 은 친숙하리라 생각된다.

프로그램은 윈도우의 `*.exe` 파일이나 Mac의 `*.dmg` 파일과 같은 **컴퓨터에서 실행 할 수 있는 파일** 을 통칭한다. 단, 아직 **파일을 실행하지 않은 상태** 이기 때문에 **`정적 프로그램(Static Program)`** 줄여서 **`프로그램(Program)`** 이라고 부른 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/1918ecd9-048f-4a5e-9895-c92481cb878f)

어떠한 프로그램을 개발하기 위해선 자바나 C언어와 같은 언어를 이용해 코드를 작성하여 완성된다.

즉, 프로그램은 쉽게 말해서 그냥 **코드 덩어리** 인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/cd47d329-23af-45bf-a19f-cbf285d1e9b3)

<br>

### 프로세스 Process
프로그램이 그냥 코드 덩어리이면, 프로세스는 프로그램을 실행 시켜 정적인 프로그램이 동적(動的)으로 변하여 **프로그램이 돌아가고 있는 상태** 를 말한다.

즉, 컴퓨터에서 **작업** 중인 프로그램을 의미하는 것이다.

이 개념은 절대 생소한 것이 아니다.
`ctrl + alt + del` 단축키를 눌러 우리가 항상 보던 '작업' 관리자를 열어보면 개념이 고대로 들어있는걸 볼 수 있을 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/14b92a3c-0f72-4274-b97c-975281bdf355)

모든 프로그램은 운영체제가 실행되기 위한 메모리 공간을 할당해 줘야 실행될 수 있다.
그래서 프로그램을 실행하는 순간 *파일은 컴퓨터 메모리에 올라가게 되고,* OS 로부터 *시스템 자원 (CPU) 를 할당*받아 프로그램 코드를 실행시켜 우리가 서비스를 이용할 수 있게 되는 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/8b791514-4cd2-4c79-a32f-8f87776bc739)

어쨋든 똑같은 어플리케이션을 실행 하냐 안하냐 차이일 뿐이라서, 일반적으로 프로세스와 프로그램을 같은 개념으로 이야기할 때가 많지만, 정의를 보았듯이 엄밀히 따지면 이 둘은 다른 개념인 것이다.

최종적으로 이 둘을 간단 명료하게 정리하면 아래 표와 같다.

![image](https://github.com/lielocks/WIL/assets/107406265/9088bc7f-8cc4-4ea4-9074-a6865714c00d)

<br>

## 스레드

### 프로세스의 한계
과거에는 프로그램을 실행할 때 `프로세스 하나만` 을 사용해서 이용했었다. 

하지만 기술이 발전됨에 따라 프로그램이 복잡해지고 다채로워짐으로써 프로세스 작업 하나만을 사용해서 프로그램을 실행하기에는 한계가 있었다.

오늘날 컴퓨터는 파일을 다운 받으며 다른 일을 하는 멀티 작업은 너무 당연한 기능이라고 생각할지 모르겠지만, 

과거에는 파일을 다운받으면 실행 시작부터 실행 끝까지 프로세스 하나만을 사용하기 때문에 다운이 완료될때까지 하루종일 기다려야 했다. 

그렇다고 **동일한 프로그램을 여러 개의 프로세스** 로 만들게 되면, 그만큼 `메모리를 차지하고 CPU에서 할당받는 자원이 중복` 되게 될 것이다. 스레드(Thread)는 이러한 프로세스 특성의 한계를 해결하기 위해 탄생 하였다.

<br>

### 스레드의 개념
스레드란, 하나의 **프로세스 내에서 동시에 진행되는 작업 갈래, 흐름의 단위** 를 말한다.

이해하기 쉽게 비유를 들자면, 크롬 브라우저가 실행되면 프로세스 하나가 생성될 것이다.
그런데 우리는 브라우저에서 파일을 다운 받으며 온라인 쇼핑을 하며 게임을 하기도 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/ec27a960-0f9e-40b5-877e-093d826852ae)

즉, 하나의 프로세스 안에서 여러가지 작업들 흐름이 동시에 진행되기 때문에 가능한 것인데, 이러한 일련의 작업 흐름들을 스레드라고 하며 여러개가 있다면 이를 멀티(다중) 스레드 라고 부른다.

아래 그림에서 보듯이 하나의 프로세스 안에 여러개의 스레드들이 들어 있다고 보면 된다. 스레드 수가 많을 수록 당연히 프로그램 속도도 동시에 하는 작업이 많아져 성능이 올라간다.

![image](https://github.com/lielocks/WIL/assets/107406265/f3090831-e52c-4077-bc0e-88bfe7f9b3b7)

일반적으로 하나의 프로그램은 하나 이상의 프로세스를 가지고 있고, 하나의 프로세스는 반드시 하나 이상의 스레드를 갖는다. 

즉, **프로세스를 생성** 하면 **`기본적으로 하나의 main 스레드가 생성`** 되게 된다. 
스레드 2개, 3개.. 는 프로그램을 개발한 개발자가 직접 프로그래밍하여 위치 시켜주어야 한다. 그래서 별도로 스레드 프로그래밍 과목이 있는 이유이기도 하다. 

<br>

## 프로세스 & 스레드의 메모리

### 프로세스의 자원 구조
프로그램이 실행되어 프로세스가 만들어지면 다음 4가지의 메모리 영역으로 구성되어 할당 받게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/44bbaf68-1015-473c-ace7-ba97d085264a)

+ **코드 영역 (Code / Text)** : 프로그래머가 작성한 프로그램 함수들의 코드가 CPU 가 해석 가능한 기계어 형태로 저장되어 있다.

+ **데이터 영역 (Data)** : 코드가 실행되면서 사용하는 전역 변수나 각종 데이터들이 모여있다. .data .rodata .bss 영역으로 세분화된다.
  + **`.data** : *전역 변수* 또는 *static 변수* 등 프로그램이 사용하는 데이터를 저장
 
  + **`.BSS`** : *초기값 없는 전역 변수* , *static 변수* 가 저장
 
  + **`.rodata`** : const 같은 상수 키워드 선언 된 변수나 문자열 상수가 저장

+ **스택 영역 (Stack)** : 지역 변수와 같은 호출한 함수가 종료되면 되돌아올 임시적인 자료를 저장하는 독립적인 공간이다. Stack 은 함수의 호출과 함께 할당되며, 함수의 호출이 완료되면 소멸한다. 만일 stack 영역을 초과하면 stack overflow 에러가 발생한다.

+ **힙 영역 (Heap)** : 생성자, 인스턴스와 같은 동적으로 할당되는 데이터들을 위해 존재하는 공간이다. 사용자에 의해 메모리 공간이 동적으로 할당되고 해제된다.

<br>

위의 그림에서 Stack과 Heap 영역이 위아래로 화살표가 쳐 있는 것을 볼 수 있는데, 이는 **`코드 영역과 데이터 영역은 선언할 때 그 크기가 결정되는 정적 영역`** 이지만, **`스택 영역과 힙 영역은 프로세스가 실행되는 동안 크기가 늘어났다 줄어들기도 하는 동적 영역`** 이기 때문에 이를 표현한 것이다.

아래 그림을 보면서 간략히 정리하자면, 프로그램이 여러개 실행된다면 메모리에 프로세스들이 담길 주소 공간이 생성되게 되고 그 안에 Code, Data, Stack, Heap 공간이 만들어지게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/ccaf3665-9404-4784-b4c2-1075037a27dd)

<br>

### 스레드의 자원 공유
스레드는 프로세스가 할당 받은 자원을 이용하는 실행의 단위로서, 스레드가 여러개 있으면 우리가 파일을 다운 받으며 동시에 웹 서핑을 할 수 있게 해준다. 

스레드끼리 **프로세스의 자원을 공유** 하면서 프로세스 실행 흐름의 일부가 되기 때문에 동시 작업이 가능한 것이다. 그래서 아래 사진과 같이 하나의 프로세스 내에 여러개의 스레드가 들어있는 상태인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/5edbb9cb-9d13-4e6d-9af6-755886128a32)

이때 프로세스의 4가지 메모리 영역(Code, Data, Heap, Stack) 중 스레드는 **Stack만 할당받아 복사** 하고 **`Code, Data, Heap`** 은 프로세스내의 다른 스레드들과 **공유** 된다. 

따라서 각각의 스레드는 **별도의 stack** 을 가지고 있지만 **heap 메모리는 고유** 하기 때문에 서로 다른 스레드에서 가져와 읽고 쓸 수 있게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/54c75e91-60d0-4f0b-9d39-edd4e46b0703)

>
> stack 은 **함수 호출 시** `전달되는 인자`, `되돌아갈 주소 값`, `함수 내에서 선언하는 변수` 등을 저장하는 메모리 공간이기 때문에,
>
> **독립적인 스택** 을 가졌다는 것은 **독립적인 함수 호출이 가능하다** 라는 의미이다.
>
> 그리고 **독립적인 함수 호출** 이 가능하다는 것은 **독립적인 실행 흐름이 추가된다** 는 말이다.
>
> 즉, ***stack 을 가짐으로써 스레드는 독립적인 실행 흐름을 가질 수 있게 되는 것*** 이다.

>
> 반면에 **`프로세스`** 는 **기본적으로 프로세스 끼리 다른 프로세스의 메모리에 직접 접근할 수는 없다.**
>

이렇게 구성한 이유는 하나의 프로세스를 다수의 실행 단위인 스레드로 구분하여 자원을 공유하고, 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 올리기 위해서다.

<br>

### 프로세스의 자원 공유
기본적으로 각 프로세스는 메모리에 별도의 주소 공간에서 실행되기 때문에, **한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수는 없다.** 

그렇다면 프로세스는 영원히 다른 프로세스 정보에 접근할 수 없을까?

현재 우리가 사용하는 대부분의 컴퓨터 프로그램을 보면 다른 프로그램에 있는 정보를 가져오는 경우는 심심치 않게 볼 수 있을 것이다. 

이처럼 특별한 방법을 통해 프로세스가 다른 프로세스의 정보에 접근하는 것이 가능하다. 프로세스 간 정보를 공유하는 방법에는 다음과 같은 방법들이 있다.

+ **IPC(Inter-Process Communication) 사용**
  
+ **LPC(Local inter-Process Communication) 사용**

+ **별도로 공유 메모리를 만들어서 정보를 주고받도록 설정**

<br>

![image](https://github.com/lielocks/WIL/assets/107406265/d8bf9b6a-b27e-4112-af63-94f553331012)

그러나 프로세스 자원 공유는 단순히 CPU 레지스터 교체뿐만이 아니라 RAM 과 CPU 사이의 캐시 메모리까지 초기화되기 때문에 **자원 부담이 크다는 단점이 있다.**

**그래서 다중 작업이 필요한 경우 스레드를 이용하는 것이 훨씬 효율적** 이라, 현대 컴퓨터의 OS 에선 다중 프로세싱을 지원하고 있지만 `다중 스레싱` 을 기본으로 하고 있다.

<br>

## 프로세스 & 스레드의 동시 실행 원리
우리가 음악을 들으면서, 웹서핑을 하고, 메신저의 메시지를 확인할 수 있는 이유는 컴퓨터 내부적으로 **프로세스와 스레드를 동시에 처리** 하는 **`멀티 태스킹(multi tasking)`** 기술 때문이다. 

하지만 여기서 동시에 처리한다는 것이 심플하게 CPU 프로세서가 프로그램들을 한꺼번에 동시에 돌리는 것으로 생각하겠지만, 내부적으로 복잡한 원리에 의해 처리가 된다. 그리고 이 원리가 운영체제 이론의 핵심 원리이기도 하다. 지금부터 그 원리에 대해 파헤쳐 보도록 하자.

![image](https://github.com/lielocks/WIL/assets/107406265/19a038df-a678-442a-8326-cc68e630b0a7)

<br>

### 멀티 코어와 스레드

한번 컴퓨터 견적을 맞춰본 경험이 있는 독자분들은 **4코어 8쓰레드** CPU에 대한 단어를 본 적이 있을 것이다. 

![image](https://github.com/lielocks/WIL/assets/107406265/1ad45abb-a56b-46e2-9add-9c5009068d43)

CPU 한 개는 여러개의 코어를 가질 수 있다. **코어** 는 말그대로 **CPU 코어 유닛** 이다.

즉, 명령어를 메모리에서 뽑아 해석하고 실행하는 반도체 유닛이 4개가 있는 것이다.
`4코어` 가 **`물리적 코어 갯수`** 면, `8쓰레드`는 **`논리적 코어 갯수`** 를 말한다.

이 경우 **물리적 코어 하나가 스레드 두개 이상을 동시에 실행 가능** 하다는 의미가 된다.

즉, OS가 8개의 작업을 동시에 처리할 수 있다는 뜻이다.
이를 **하이퍼 스레딩 (Hyper-Threading)** 기술이라 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/039f4a59-ab1b-432d-81d3-9409d48a0dfb)

>
> 단, 여기서 CPU 의 쓰레드는 우리가 배운 프로세스의 스레드와는 조금 다른 개녀이다.
>
> 엄밀히 말하자면 CPU 의 스레드는 하드웨어적 스레드이고 프로그램의 스레드는 소프트웨어적 스레드로 구분한다.

<br>

그런데 우리는 컴퓨터를 이용할때 프로그램을 수십, 수백개를 켜 놓고 이용한다. 그럼 그 수십수백개의 프로세스들을 고작 8개의 논리적인 스레드도 어떻게 처리하는 것일까?

이 원리를 알기위해선 **병렬성(Parallelism)** 과 **동시성(Concurrency)** 이라는 개념을 알고 있어야 한다. 이 개념은 운영체제의 프로세스, 스레드를 이해하는데 있어 가장 핵심 골자가 되는 녀석들이다.

<br>

## CPU 의 작업 처리 방식

### 병렬성 (Parallelism)

병렬성은 직관적으로 명령어를 메모리아서 뽑아 해석하고 실행하는 반도체 유닛인 여러개의 코어에 맞춰 여러개의 프로세스, 스레드를 돌려 병렬로 작업들을 동시 수행하는 것을 말한다.

![image](https://github.com/lielocks/WIL/assets/107406265/bae5eaf5-2504-4d13-a3ab-96e5363e80fc)

듀얼코어, 쿼드코어, 옥타코어 등등 이런 명칭이 붙는 멀티코어 프로세서가 달린 컴퓨터에서 할 수 있는 방식이다.

![image](https://github.com/lielocks/WIL/assets/107406265/423af1cc-95d6-4b45-a7df-573f38da345d)

<br>

### 동시성 (Concurrency)
동시성은 **둘 이상의 작업이 동시에 실행되는 것** 을 의미한다. 이 '동시' 라는 의미에서 병렬성과 동시성의 한글 의미가 헷갈릴수 있다. Parallelism가 물리적으로 정말로 동시에 실행하는 것이라고 하면, Concurrency는 **동시에 실행하는 것처럼 보이게 하는 것** 으로 이해하면 된다.

즉, 1개의 코어가 있고 4개의 작업이 있다고 가정하다면, 아래 그림과 같이 프로세스들을 ​**계속 번갈아가면서 조금씩 처리함** 으로써 마치 프로그램이 **동시에 실행되는 것처럼 보이는 것** 이다. 

이때 프로세스들을 ​번갈아가면서 매우 빠르게 처리하기 때문에 컴퓨터를 모르는 사람들이 보면 마치 동시에 돌아가는 것처럼 보이게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/d39ad2c7-52d9-44f2-83ac-26fe437455e4)

단, 이때 작업들을 번갈아가면서 실행할때 작업들을 **아주 잘게 나누어 아주 조금씩만 작업을 수행하고 다음 작업으로 넘어가는 식** 으로 동작된다. 

이렇게 하는 이유는 여러 작업을 동시에 처리하는 것처럼 보이게 만들어, 사용자에게 더 빠른 반응성을 제공하기 위해서다. 그리고 이렇게 진행 중인 작업들을 A → B → C → D 로 번갈아 바꾸는 것을 **`Context Switching`** 이라고 부른다.

![image](https://github.com/lielocks/WIL/assets/107406265/d1085f86-0024-420c-be24-f4ce0e737f88)

<br>

### 동시성이 필요한 이유
그런데 상식적으로 생각해보면 동시성(Concurrency)은  '동시에 돌아가는 것 처럼' 보이는 거지, 정말 실제로 동시에 돌아가는 것이 아니기 때문에 최종 작업이 걸리는 시간은 거의 차이가 없을 것이다. 

병렬성은 정말로 각 코어에 프로세스를 나눠 실행하는 거니까 듀얼 코어면 반 이상 줄어들텐데 말이다. 그렇다면 왜 이렇게 번거롭게 작업들을 스위칭 하며 처리하는 것일까?

첫번째는 **하드웨어적 한계** 때문이라고 할 수 있다. 

CPU 발열 때문에 깡 클럭으로 성능을 올리기에는 한계에 봉착됬기 때문에 코어의 성능을 올리는 대신 **코어를 여러개 탑재** 하여 쿼드 코어, 옥타 코어 CPU들을 출시하고 있다. 하지만 아무리 코어를 많이 넣어도 `수십개의 코어를 넣은순 없으니` 결국 하드웨어적 제한이 걸리게 되고 수십수백개의 프로세스를 돌리기 위해선 결국 동시성이 필요한 것이다.

두번째는 보다 **논리적인 효율적인 이유** 에서이다. 

4코어 8스레드의 CPU 환경에서 현재 총 16개의 작업이 있다고 가정을 해보자. 그중 8개는 오래 걸리는 작업이고, 나머지 8개는 짧은 시간을 필요로 하는 작업이라고 한다. 논리적인 8개의 코어이니 최대 8개까지 동시에 실행할수 있을텐데, 만일 최악의 경우 8개의 오래 걸리는 작업이 먼저 동시에 처리되기 시작했다고 하자. 이 경우 나머지 가벼운 8개의 작업은 처리하는데 짧은 시간이 걸리는 데에도 불구하고 **현재 처리중인 8개의 작업이 다 끝날때 까지 기다려야 할 것** 이다. 
따라서 이러한 비효율적인 면을 극복하기 위해 **작업을 아주 잘게 나눠 번갈아 가면서 처리하는 동시성 개념** 을 채택한 것이다.

따라서 최대 8개의 작업에 대해서 8개의 논리적인 스레드가 병렬적으로 아주 빠르게 동시적으로 작업을 하면서, 그보다 많은 수십개의 소프트웨어적 스레드가 있다면 적절히 병렬성과 동시성을 섞어 동시에 돌리게 되게 된다.

<br>

## 프로세스 & 스레드의 생명 주기
프로세스와 스레드는 각각의 생명 주기를 가지고 있으며, 운영체제는 이러한 생명 주기를 관리하고, 프로세스와 스레드를 조정하여 시스템 자원을 효율적으로 사용할 수 있게 된다.
 
### 프로세스 스케쥴링
프로세스 스케줄링(Process Scheduling)은 운영체제에서 CPU를 사용할 수 있는 프로세스를 선택하고, CPU를 할당하는 작업을 말한다. 프로세스 스케줄링은 프로세스의 우선순위, 작업량 등을 고려하여 효율적으로 배치하여, 이를 통해 운영체제는 CPU를 효율적으로 사용하며 시스템 전반적인 성능을 향상시킨다. 그래서 스케줄링은 멀티 태스킹 작업을 만들어내는 데에 있어서 핵심적인 부분이다.

스케쥴링은 운영체제의 특징과 시스템 요구사항에 따라 다양한 알고리즘 방식으로 동작된다. 알고리즘 종류로는 대표적으로 **FCFS(First-Come, First-Served)** **SJF(Shortest-Job-First)** **Priority** **RR(Round-Robin)** **Multilevel Queue** 등이 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/fa3af473-78e3-44e4-8563-03949945e9c8)

<br>

### 프로세스 상태
프로세스의 상태는 프로세스가 실행되는 동안 변경되는 고유 상태를 의미한다. 프로세스가 생성되어 실행하기 까지 프로세스는 여러가지의 상태를 갖게 되고, 상태의 변화에 따라 프로세스가 동작되는 것이다. 프로세스는 일반적으로 다음과 같은 5가지 상태를 가진다.

![image](https://github.com/lielocks/WIL/assets/107406265/7ab59a00-3a20-4915-9b22-00d78e389c6a)

<br>

### 프로세스 상태 전이
프로세스 상태 전이란 **프로세스가 실행되는 동안 상태가 OS에 의해 변경되는 것** 을 말한다. 
운영체제는 프로세스의 상태를 감시하고, 프로세스 상태를 기반으로 프로세스 스케쥴링을 통해 프로세스를 관리하고 제어한다. 

예를 들어, `READY 상태에 있는 여러 프로세스 중` 에서 `어떤 프로세스를 RUNNING 상태` 로 바꿀지, `TERMINATED 상태에 있는 프로세스를 제거` 하고 `READY 상태에 있는 다른 프로세스를 선택할지` 스케쥴링 알고리즘에 의해 동작된다.

![image](https://github.com/lielocks/WIL/assets/107406265/164e1945-0599-4d90-81dd-5afd70728e91)

1. **Admitted (new -> ready)** : 프로세스 생성을 승인 받음

2. **Dispatch (ready -> running)** : 준비 상태에 있는 여러 프로세스들 중 하나가 스케줄러에 의해 **실행** 됨

3. **Interrupt (running -> ready)** : **Timeout** , 예기치 않은 이벤트가 발생하여 **현재 실행 중인 프로세스를 준비 상태로 전환** 하고, **해당 이벤트를 먼저 처리**

4. **I/O or event wait (running -> waiting)** : 실행 중인 프로세스가 **입출력이나 이벤트를 처리** 해야 하는 경우, **입출력이나 이벤트가 끝날때까지 대기 상태** 로 전환

5. **I/O or event completion (waiting -> ready)** : **입출력이나 이벤트가 모두 끝난 프로세스** 를 **다시 준비 상태** 로 만들어 스케줄러에 의해 **선택될 수 있는 상태** 로 전환

<br>

### 프로세스 컨텍스트 스위칭
컨텍스트 스위칭(Context Switching)은 **`CPU가 한 프로세스에서 다른 프로세스로 전환할 때 발생하는 일련의 과정`** 을 말한다. 

위의 동시성 (Concurrency) 파트에서 다뤘듯이 **CPU는 한 번에 하나의 프로세스만 실행** 할 수 있으므로, ***여러 개의 프로세스를 번갈아가며 실행하여 CPU 활용률을 높이기 위해 컨텍스트 스위칭*** 이 필요한 것이다.

컨텍스트 스위칭을 좀더 구체적으로 말하자면, 

**`동작 중인 프로세스가 대기`** 를 하면서 **해당 프로세스의 상태(Context)를 보관** 하고, 
**`대기하고 있던 다음 순서의 프로세스가 동작`** 하면서 **이전에 보관했던 프로세스의 상태를 복구하는 작업** 을 말한다. 

이러한 컨텍스트 스위칭이 일어날 때 다음번 프로세스는 스케줄러가 결정하게 된다. 
즉, **컨텍스트 스위칭을 하는 주체** 는 **스케줄러** 이다.

![image](https://github.com/lielocks/WIL/assets/107406265/9fb85a4e-a813-44b3-b765-90da3580d5be)

<br>

### PCB (Process Control Block)
PCB(프로세스 제어 블록)는 운영체제에서 프로세스를 관리하기 위해 **해당 프로세스의 상태 정보** 를 담고 있는 자료구조를 말한다.

프로세스를 컨텍스트 스위칭 할때 `기존 프로세스의 상태를 어딘가에 저장` 해 둬야 `다음에 똑같은 작업을 이어서 할 수 있을 것` 이고, `새로 해야 할 작업의 상태` 또한 알아야 `어디서부터 다시 작업을 시작할지` 결정할 수 있을 것이다. 

즉, PCB는 **`프로세스 스케줄링`** 을 위해 ***프로세스에 관한 모든 정보 저장하는 임시 저장소*** 인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/a5fede1c-69f9-498b-a016-e4318fd0035f)

따라서 운영체제는 **`PCB에 담긴 프로세스 고유 정보`** 를 통해 **프로세스를 관리** 하며, 

**`프로세스의 실행 상태를 파악`** 하고, **`우선순위를 조정`** 하며, **`스케줄링을 수행`** 하고, **`다른 프로세스와의 동기화를 제어`** 한다.

운영체제에 따라 PCB에 포함되는 항목이 다를 수 있지만 일반적으로 PCB내 에는 다음과 같은 정보가 포함되어 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/6797ef2a-f892-41a0-b0a0-8c3b0a52a108)

+ **포인터 (Pointer)** : 프로세스의 현재 위치를 저장하는 포인터 정보

+ **프로세스 상태 (Process State)** : 프로세스의 각 상태 -> 생성(New), 준비(Ready), 실행(Running), 대기(Waiting), 종료(Terminated) 를 저장

+ **프로세스 아이디 (Process ID, PID)** : 프로세스 식별자를 지정하는 고유한 ID

+ **프로그램 카운터 (Program Counter)** : 프로세스를 위해 **실행될 다음 명령어의 주소를 포함하는 카운터** 를 저장

+ **레지스터 (Register)** : 누산기, 베이스, 레지스터 및 범용 레지스터를 포함하는 CPU 레지스터에 있는 정보

+ **메모리 제한 (Memory Limits)** : 운영 체제에서 사용하는 메모리 관리 시스템에 대한 정보

+ **열린 파일 목록 (List of Open File)** : 프로세스를 위해 열린 파일 목록

<br>

### Context Switching 과정
두 개의 프로세스 간에 컨텍스트 스위칭 과정을 그림으로 표현한 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/e60e2f2b-859c-49ee-b019-3cccc047e129)

1. CPU 는 Process P1 을 실행한다. (Executing)

2. 일정 시간이 지나 Interrupt 또는 System Call 이 발생한다. (CPU 는 idle 상태)

3. 현재 실행 중인 Process P1의 상태를 PCB 1에 저장한다. (Save state into PCB1)

4. 다음으로 실행할 Process P2를 선택한다. (CPU 스케줄링)

5. Process P2의 상태를 PCB2에서 불러온다. (Reload state from PCB2)

6. CPU는 Process P2를 실행한다. (Executing)

7. 일정 시간이 지나 Inerrupt 또는 Systme Call 이 발생한다. (CPU 는 idle 상태)

8. 현재 실행 중인 Process P2의 상태를 PCB2에 저장한다. (Save state into PCB2)

9. 다시 Process P1을 실행할 차례가 된다. (CPU 스케줄링)

10. Process P1의 상태를 PCB1에서 불러온다. (Reload state from PCB1)

11. CPU는 Process P1을 중간 시점 부터 실행한다. (Executing)

> idle (대기) 와 executing (실행) 은 CPU 의 동작 상태를 나타낸 것이다.

<br>

### Context Switching Overhead
이러한 컨텍스트 스위칭 과정은 사용자로금 빠른 반응성과 동시성을 제공하지만, 실행되는 **프로세스의 변경 과정** 에서 `프로세스의 상태, 레지스터 값 등이 저장되고 불러오는 등의 작업` 이 수행하기 때문에 시스템에 많은 부담을 주게된다.

위의 컨텍스트 스위칭 과정 그림을 보면 **`P1이 Execute에서 idle이 될 때`** **`P2가 바로 Execute가 되지 않고 idle을 상태에 조금 있다가`** **Execute** 가 되는걸 볼 수 있다. 

**이 간극** 이 바로 ***컨텍스트 스위칭 오버헤드(overhead)*** 인 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/d5d60303-1c2f-4bc3-ae11-827e3314da21)

컨텍스트 스위칭 오버헤드는 대표적으로 다음과 같은 행위에 의해서 발생된다.

+ **PCB 저장 및 복원 비용**

+ **CPU 캐시 메모리 무효화** 에 따른 비용

+ **프로세스 스케줄링** 비용

<br>

컨텍스트 스위칭 과정에서 **PCB를 저장하고 복원하는데 비용** 이 발생하며, ***프로세스 자체가 교체되는 것*** 이니 **`CPU의 캐시 메모리에 저장된 데이터가 무효화`** 가 된다. 
이 과정에서는 **메모리 접근 시간** 이 늘어나고, **성능 저하** 가 발생할 수 있다. 
또한 **CPU 스케줄링 알고리즘** 에 따라 프로세스를 선택하는 비용도 만만치 않다.

바로 뒤에서 다루겠지만, 컨텍스트 스위칭은 꼭 프로세스 뿐만 아니라 **여러개의 스레드들 끼리도 스위칭** 이 일어난다. 보통 **`멀티 스레드`** 라고 하면 여러개의 스레드가 동시에 돌아가니 프로그램 성능이 무조건 상승할거라 예상하지만, 이는 정확하지 않다. **`컨텍스트 스위칭 오버헤드`** 라는 변수 때문에 스레드 교체 과정에서 과하게 오버헤드가 발생하면 **오히려 멀티 스레드가 싱글 스레드보다 성능이 떨어지는 현상** 이 나타날수 있기 때문이다.

<br>

## 스레드 스케줄링
프로세스 스케쥴링과 마찬가지로, 스레드 스케줄링(Thread Scheduling)은 **`운영체제에서 다중 스레드를 관리`** 하며, **`CPU를 사용할 수 있는 스레드를 선택`** 하고, **`CPU를 할당하는 작업`** 을 말한다.

**`스레드의 우선순위, 실행 시간, 입출력 요청 등의 정보`** 를 고려하여 **CPU를 사용할 수 있는 스레드를 선택하는** 스레드 스케줄링 알고리즘은 프로세스 스케줄링 알고리즘과 유사하게 동작한다. 

다양한 알고리즘이 있으며, 대표적으로는 **Round Robin** **Priority-based scheduling** **Multi-level Queue scheduling** 등이 있다.

다만 **스레드 스케줄링** 은 프로세스 스케줄링과 다르게, ***하나의 프로세스 내에서 다수의 스레드가 동작*** 하는 형태이기 때문에, **스레드 간의 상호작용과 동기화 문제를 고려** 해야 한다는 차이점이 존재한다.

![image](https://github.com/lielocks/WIL/assets/107406265/721e5efa-455f-4b6f-88f2-48e627191074)

<br>

### 스레드 상태
프로세스 상태와 마찬가지로, 스레드에도 상태가 있다. 일반적으로 다음과 같은 4가지 상태를 가진다.
![image](https://github.com/lielocks/WIL/assets/107406265/1a26f6f4-0efd-49d9-9d38-e5f9cfd9abd5)

<br>

### 스레드 상태 전이
스레드 상태 전이에 대한 제어는 자바와 같은 스레드 프로그래밍에서 자세히 다루게 될 것이다.

![image](https://github.com/lielocks/WIL/assets/107406265/823d209e-e822-42f4-9762-afe6c54900da)

<br>

## 스레드 컨텍스트 스위칭
스레드 컨텍스트 스위칭(thread context switching)은 **`멀티 스레딩 환경`** 에서 **스레드 간의 실행을 전환** 하는 기술이다. 

프로세스 컨텍스트 스위칭과 다른점은 스레드 컨텍스트 스위칭은 **하나의 프로내스 내의 스레드들을 교환한다** 는 점이다.
![image](https://github.com/lielocks/WIL/assets/107406265/548b3bcc-2761-49de-b34e-a7c21ed903bb)

<br>

### TCB (Thread Control Block)
PCB 처럼, TCB(스레드 제어 블록)는 **각 스레드마다 운영 체제에서 유지하는 스레드에 대한 정보** 를 담고 있는 자료구조이다. 

그림에서 볼 수 있듯이 **`TCB는 PCB 안에`** 들어있다. 

**스레드가 프로세스 내에 위치한 것 처럼 말이다.**

![image](https://github.com/lielocks/WIL/assets/107406265/28ea7fde-f391-417f-9764-8dc36bc845d0)

역시 스레드의 상태 정보, 스레드 ID, 스레드 우선순위, 스케줄링 정보 등 다양한 정보를 저장한다.
TCB도 스레드가 생성될 떄 OS에 의해 생성되며, 스레드가 실행을 마치고 소멸될 때 함께 소멸된다.

또한 **스레드 간의 자원 공유와 동기화** 도 **`TCB`** 를 사용하여 관리된다.

예를 들어 뮤텍스 (mutual exclusion) 나 세마포어 (semaphore) 와 같은 동기화 기법을 사용할 때, TCB에서 해당 스레드의 뮤텍스나 세마포어 정보를 관리하고, ***스레드가 해당 자원에 대한 접근 권한을 획득하거나 반납할 때*** *TCB의 정보를 업데이트하게 된다.*

> **뮤텍스 (mutex)**
>  **임계 구역에 1개의 스레드만** 들어갈 수 있는 동기화 기법
>
> **세마포어 (semaphore)**
>  **임계 구역에 여러 스레드** 가 들어갈 수 있고, **`counter`** 를 두어서 ***허용 가능한 스레드를 제한*** 하는 기법

<br>

### 프로세스 컨텍스트 스위칭 vs 스레드 컨텍스트 스위칭
프로세스 컨텍스트 스위칭과 스레드 컨텍스트 스위칭은 모두 멀티태스킹 환경에서 여러 프로세스 또는 스레드를 동시에 실행하기 위한 기술이다. 그러나 두 기술은 몇 가지 차이점이 있다.
 
**1. TCB 가 PCB 보다 가볍다.**

결론부터 말하자면, 스레드 컨텍스트 스위칭이 프로세스 컨텍스트 스위칭보다 더 빠르다.
위에서 프로세스와 스레드의 메모리 섹션에서 다뤘듯이, 프로세스 내의 스레드들은 text, data, heap 영역 메모리를 공유하기 때문에 TCB에는 stack 및 간단한 register 포인터 정보만을 저장하기 때문에 PCB보다 TCB가 가벼워 더 빨리 읽고 쓸수 있다.

<br>

**2. 캐시 메모리 초기화 여부**

**CPU 캐쉬 메모리** 는 `CPU와 메인 메모리 사이에 위치` 하며 **CPU에서 한번 이상 읽어들인 메모리의 데이터를 저장** 하고 있다가, `CPU가 다시 그 메모리에 저장된 데이터를 요구` 할 때, **메인 메모리를 통하지 않고 곧바로 데이터를 전달해 주는 용도** 이다.

그런데 **`프로세스 컨텍스트 스위칭`** 이 일어날 경우, ***다른 프로세스의 실행*** 으로 인해 **`CPU가 새로운 명령어와 데이터를 로드`** 해야 하기 때문에 **CPU 캐시 메모리를 초기화** 하여야 한다. 이것이 프로세스 컨텍스트 스위칭에 `부담이 되는 요소`이다.

**`스레드 컨텍스트 스위칭`** 일 경우, 프로세스 내 스레드 간에 **스택과 레지스터 값 등 일부 컨텍스트 정보만 변경** 되므로 **CPU 캐시 메모리는 초기화되지 않는다.** 

다만 스레드가 `다른 CPU 코어에서 실행될 때` 는 **해당 코어의 캐시 메모리에 스레드 컨텍스트 정보가 로드** 되어야 하므로 `초기화될 수 있다.`

<br>

**3. 자원 동기화 문제**

**`스레드 컨텍스트 스위칭`** 이 발생해 **다른 스레드가 heap 영역의 공유 데이터에 접근** 할때, ***이전 스레드가 이미 공유 자원을 사용하고 있는 경우*** **`동기화 문제`** 가 발생할 수 있다. 

예를 들어, **두 개의 스레드가 동시에 하나의 변수를 수정** 하려고 할 때, 스레드 컨텍스트 스위칭이 발생하면**변수의 값을 잘못된 값으로 업데이트** 할 수 있는 것이다. 

이것을 스레드 간에 **`경쟁 조건 (race condition)`** 이라고 한다.

`프로세스는 기본적으로 독립된 공간` 이지만, **IPC와 같은 공유 자원을 사용하는 경우** 에 ***똑같이 경쟁 조건이 발생*** 할 수가 있다. 

예를 들어, 여러 개의 프로세스가 동시에 파일 시스템에 접근하여 파일을 수정하려고 할 때, 컨텍스트 스위칭이 발생할 때 다른 프로세스가 그 파일에 접근할 수 있기 때문에 파일 내용이 손상될 수 있다.

따라서 이들을 해결하기 위해선 각 상황에 적절한 공유 자원에 대한 동기화 메커니즘**이 필요해진다.

<br>

# 개요 

+ **프로세스**란, 실행 중인 프로그램을 말한다.

+ 우리가 사용하는 컴퓨터에서는 정말 많은 **프로세스**들이 실행되고 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/5e26059b-d83d-443a-98c9-fa80dfc6427f)

+ 프로세스들은 실행을 위해 **CPU, Memory 등의 자원** 들을 **OS**로부터 할당받아 사용한다.

+ 운영체제가 프로세스들에게 효율적으로 자원을 할당하는 것을 **프로세스 스케줄링**이라고 한다.

<br>

## 프로그램

+ 프로그램이란, **`명령어들의 집합`** 이다.

+ 여기서 말하는 명령어는 CPU가 실행하는데 필요한 명령어이다.

+ 즉, 프로그래밍 언어로 작성된 소스 코드를 컴파일하여 만들어진 **명령어들의 집합** 이다.
  + Ex) UNIX 계열 운영체제의 `.out 파일`, Windows 운영체제의 `.exe 파일`

+ 프로그램은 **보조기억장치** 에 저장되어 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/20730fab-f244-44d9-9676-53acd8339273)

<br>

## 프로세스 Process
+ **프로그램이 실행되어 메모리에 적재된 상태** 를 말한다.

+ **실행 중인 프로그램** 이라고 볼 수 있다.
  + Ex) 게임 프로그램(실행파일) 실행 → 게임 프로세스 생성.

+ 프로세스 생성 시, **OS**가 프로세스에 필요한 **자원을 할당**한다.

+ 이때, 프로세스들은 각각의 **독립된 메모리 영역** 을 할당 받는다.
  + 각 프로세스들은 자신만의 독립된 메모리 영역을 가지고 있으므로, ***프로세스 간 통신은 불가능하다.***
 
  + **`프로세스 간 통신`** 을 위해서는 **`파이프, 시그널, 공유메모리, 파일`** 등을 사용해야 한다.
    ![image](https://github.com/lielocks/WIL/assets/107406265/b5074035-3933-48a2-b459-a0198de09dd9)

<br>

## 프로세스 제어 블록 (Process Control Block)
+ **프로세스와 관련된 정보**를 저장하는 곳이다.

+ 각 프로세스마다 자신만의 PCB를 가지고 있다.

+ 프로세스 ID(PID), 프로세스 상태 등의 정보들을 저장하고 있다.

+ 운영체제는 **PCB를 통해 각 프로세스를 식별** 한다.

+ PCB는 중요한 정보들을 저장하고 있기 때문에, **커널 메모리 영역에 저장**된다.
  + **`커널 메모리 영역 (OS 영역)`** : **시스템에서 사용해야 하는 필수적인 데이터** 나 중요한 정보들을 저장하기 위해 사용하는 메모리 영역
  + **`사용자 메모리 영역`** : **각 프로세스가 할당 받는** 메모리 영역 (Code Data Heap Stack)

![image](https://github.com/lielocks/WIL/assets/107406265/3dfbf854-2eff-4c5a-9c20-2ce2da3b429d)

+ **PCB에 저장되는 정보들**은 아래와 같다.
  + **프로세스 ID (PID)** : 프로세스 식별 번호
 
  + **레지스터 값** : 프로세스가 사용하던 레지스터 값 (프로그램 카운터 등)
 
  + **프로세스 상태** : CPU를 사용 중인 상태인지, CPU 사용을 위해 기다리는 상태인지 등

  + **CPU 스케줄링 정보** : 언제, 어떤 순서로 CPU를 할당 받을지
 
  + **메모리 관리 정보** : 프로세스가 적재된 메모리 위치
 
  + **사용한 파일 및 입출력 장치 정보** : 프로세스가 어떤 입출력 장치나 파일을 사용했는지

<br>

## 문맥 교환 Context Switching
+ 모든 프로세스들은 실행을 위해 CPU 자원이 필요하지만, **CPU 자원은 한정**되어 있다.

+ 따라서 **모든 프로세스는 동시에 CPU 사용이 불가능**하며, 프로세스들은 **차례대로 돌아가면서** 특정 시간 동안 PCU를 사용한다.

+ 즉 프로세스들은 **운영체제가 할당해준 특정 시간만큼 번갈아가면서** CPU를 사용한다.

+ 이때 실행 중이던 프로세스에서 다른 프로세스로 실행 순서가 넘어갈 때, 운영체제는 **현재까지 실행 중이던 프로세스의 정보를 PCB에 저장하고**,
  **다음에 실행할 프로세스의 정보를 해당 프로세스의 PCB로부터 불러온다.***

+ 이 과정을 **문맥 교환**이라고 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/74122b47-4234-4e2a-99bc-3b95de2d6b97)

+ 문맥 교환은 **아주 빠르게 수행**되기 때문에 (현대 시스템에서는 수십 usec 정도), 사용자 입장에서는 여러개의 프로세스가 **동시에 실행되고 있는 것처럼 보인다.**

+ 문맥 교환이 자주 일어나게 된다면, 그만큼 **오버헤드**가 발생할 수 있다.
  + 오버헤드 : 특정 기능을 수행하는데 추가적으로 시간, 자원이 소모되는 것

<br>

## 프로세스 상태 Process Status

+ 프로세스가 실행될 때, 각 프로세스는 **여러 가지의 상태를 거치며 실행**된다.
![image](https://github.com/lielocks/WIL/assets/107406265/8680f95f-e617-43b7-a0b6-476dd41b60e8)
  1. 생성 상태 (NEW) : 프로세스가 이제 막 **메모리에 적재되어 PCB를 할당 받은 상태**
 
  2. 준비 상태 (READY) : CPU를 할당 받으면 실행이 가능하지만, 자신의 **차례를 기다리는 상태**
 
  3. 실행 상태 (RUNNING) : CPU를 할당 받아 **실행 중인 상태**
     + **일정 시간 동안**만 CPU 사용이 가능하다.
    
     + 할당된 시간을 모두 사용하면 **타이머 인터럽트**가 발생하며 다시 준비 상태로 변경된다.

  4. 대기 상태 (WAITING) : 입출력 요청을 받게 되어 입출력 작업을 완료할 때까지 **대기하는 상태**
     + 입출력 작업이 끝나고 **입출력 완료 인터럽트**를 받을 때까지 대기하는 상태이다.
    
     + 정확히는 **특정 이벤트가 일어나기까지 기다리는 것**이며, 대부분의 이벤트가 입출력 작업이다.
    
  5. 종료 상태 (END) : 프로세스가 종료된 상태

<br>

## 프로세스 스케줄링 Process Scheduling
+ 운영체제가 **프로세스들에게 공정하고 합리적으로 자원을 배분하는 것**을 말한다.

+ 특정 자원의 할당을 원하는 프로세스들은 해당 자원의 **스케줄링 큐**에서 대기한다.
  + 대표적인 스케줄링 큐에는 **준비큐**와 **대기큐**가 있다.
    + **`준비 큐`** : **CPU 사용**을 위해 기다리는 큐
    + **`대기 큐`** : **입출력 장치 사용**을 위해 기다리는 큐
![image](https://github.com/lielocks/WIL/assets/107406265/9d125542-cffd-4efd-8e5d-ef23e200fc34)
  + 스케줄링 큐는 반드시 선입선출(FIFO) 방식은 아니며, **프로세스들이 대기하는 공간**일 뿐이다.

+ 운영체제는 스케줄링 큐에서 대기하는 각 프로세스들의 **우선순위**를 고려하여 자원을 배분한다.
![image](https://github.com/lielocks/WIL/assets/107406265/4ad092a6-9381-426f-9e4d-37b2898a759b)
![image](https://github.com/lielocks/WIL/assets/107406265/73c23f91-4d90-4f6b-9e6e-5a4224cccfb0)
![image](https://github.com/lielocks/WIL/assets/107406265/5c8520c3-ccb5-45cf-ae4a-4820006045ae)

<br>

## 프로세스 스케줄링 알고리즘 Process Scheduling Algorithm

+ 운영체제가 **프로세스 스케줄링을 위해 사용하는 실질적인 방법**이다.

+ 대표적인 CPU 할당을 위한 프로세스 스케줄링 알고리즘의 종류는 아래와 같다.


1. **선입 선처리 스케줄링**
     + 준비 큐에 삽입된 순서대로 CPU를 할당해주는 방식이다.
    
     + 먼저 실행되는 프로세스들의 실행 시간이 길다면, 대기 중인 프로세스들이 기다리는 시간이 매우 길어질 수 있다.

<br>

  2. **최단 작업 우선 스케줄링**
     + 실행 시간이 가장 짧은 프로세스부터 CPU를 할당해주는 방식이다.

<br>

  3. **라운드 로빈 스케줄링**
     + **준비 큐에 삽입된 순서대로 PCU를 할당**하지만, **정해진 시간 (타임 슬라이스) 만큼만 할당**해주는 방식이다.
    
     + 정해진 시간동안 전부 실행되지 못했다면, 맨 마지막 순서로 돌아가서 다시 기다린다.
     ![image](https://github.com/lielocks/WIL/assets/107406265/1320eafb-d99e-40ae-8d0c-b161e323c0a0)

<br>

  4. **최소 잔여 시간 우선 스케줄링**
    + 정해진 시간만큼 CPU를 할당하되, 다음 프로세스는 남은 작업 시간이 가장 적은 프로세스를 선택하는 방식이다.

<br>

  5. **우선순위 스케줄링**
     + 프로세스들에 우선순위를 부여하고, 우선순위가 높은 프로세스부터 실행시키는 방식이다.
    
     + 우선순위가 같다면, `선입 선처리`로 처리한다.
    
     + 우선순위가 낮은 프로세스는 무한정 실행되지 못하는 `기아(Starvation) 현상`이 발생한다.
    
     + 기아 현상 방지를 위해 오래 기다린 프로세스의 우선순위를 점차 높이는 에이징 (Aging) 기법을 사용한다.

<br>

  6. **다단계 큐 스케줄링 Multilevel Queue Scheduling**
     + 우선순위별로 준비 큐를 여러개 사용하는 스케줄링 방식이다.
    
     + 우선순위가 가장 높은 큐에 있는 프로세스를 먼저 처리한다.
    
     + 우선순위가 가장 높은 큐가 비어 있으면, 그 다음 우선순위 큐를 처리한다.
    
     + 우선 순위가 낮은 프로세스는 기아 현상이 발생할 수 있다.

     ![image](https://github.com/lielocks/WIL/assets/107406265/1dfd987d-875e-431b-9a10-b657320030f2)

<br>

  7. **다단계 피드백 큐 스케줄링**
     + **큐 간의 이동**이 가능한 다단계 큐 스케줄링이다.
    
     + **우선순위**가 가장 높은 큐부터 처리를 하되, 일정 시간(타임 슬라이스)동안 못 끝낸 경우 **그 다음 우선 순위 큐**로 다시 이동하여 대기한다.
    
     + CPU 사용 시간이 길수록 우선 순위가 내려가게 된다.
    
     + 즉, **`CPU 사용 시간이 긴 CPU 집중(CPU Bound) 프로세스는 우선 순위가 상대적으로 낮아지고,`**
       **`CPU 사용 시간이 짧고 입출력 작업이 많은 입출력 집중(I/O Bound) 프로세스는 우선 순위가 상대적으로 높아진다.`**
       ![image](https://github.com/lielocks/WIL/assets/107406265/f30e7a9a-a9b1-49d1-88c9-22243da2b522)

     + 또한, 에이징 기법을 통해 기아 현상을 방지한다.
       ![image](https://github.com/lielocks/WIL/assets/107406265/d49893bf-581e-4d89-8797-5a0282942ddc)
       ![image](https://github.com/lielocks/WIL/assets/107406265/ee68b22d-46b9-442a-adfd-c546f017464d)

<br>

# 멀티 프로세스 vs 멀티 스레드
멀티 프로세스와 멀티 스레드는 **한 어플리케이션에 대한 처리방식** 이라고 보면 된다.
단순히 프로그램을 여러개 띄워놓는 것이 펄티 프로세스가 아니라 이 둘은 언제 어느때에 어떤 방식으로 처리하느냐에 따라 다른 것으로 이해해야 한다.

이름으로 유추할 수 있듯이 멀티 프로세스와 멀티 스레드는 여러개의 프로세스, 스레드가 동작하는 것을 일 컫는다. 단일이 아닌 다중으로 돌아감으로써 성능 향상 등 여러가지 효과를 얻을 수 있다. 하지만 또한 이로 인해 발생되는 부가적인 문제점도 발생하게 된다. 지금 부터 이에 대해 자세히 알아보자

![image](https://github.com/lielocks/WIL/assets/107406265/861c644a-3844-4a83-8265-bc4c7c403044)

<br>

## Multi Process
멀티 프로세스는 운영체제에서 하나의 응용 프로그램에 대해 동시에 여러 개의 프로세스를 실행할 수 있게 하는 기술을 말한다. 

보통 하나의 프로그램 실행에 대해 하나의 프로세스가 메모리에 생성되지만, 부가적인 기능을 위해 여러개의 프로세스를 생성하는 것이다.

>
> **멀티 프로세스 vs 멀티 프로세서**
>
> **`프로세스(process)`** 는 **프로그램의 실행 상태**를 말하고, **`프로세서(processer)`** 는 **CPU 코어**를 일컫는다.
>
> 둘이 단어가 유사해서 굉장히 혼동할 수 있을텐데, 어쨋든 둘이 의미하는 바는 완전히 다르다고 보면 된다.
>
> 따라서 **`멀티 프로세스`** 는 하나의 프로그램에서 여러 개의 프로세스를 실행하는 것을 의미하고, **`멀티 프로세서`** 는 여러 개의 CPU 코어가 하나의 시스템에서 동시에 실행되는 것을 의미한다.

<br>

멀티 프로세스 내부를 보면, 하나의 부모 프로세스가 여러 개의 자식 프로세스를 생성함으로서 다중 프로세스를 구성하는 구조이다. 

한 프로세스는 실행되는 도중 프로세스 생성 시스템 콜을 통해 새로운 프로세스들을 생성할 수 있는데, `다른 프로세스를 생성하는 프로세스`를 **부모 프로세스(Parent Process)** 라 하고, `다른 프로세스에 의해 생성된 프로세스`를 **자식 프로세스(Child Process)** 라 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/b2669f92-5842-4dfa-914b-8a29b238bca5)

부모 프로세스와 자식 프로세스는 **`각각 고유한 PID(Process ID)`** 를 가지고 있다. 

부모 프로세스는 자식 프로세스의 PID를 알고 있으며, 이를 통해 자식 프로세스를 제어할 수 있다. 
또한, 자식 프로세스는 부모 프로세스의 PID와 PPID(Parent Process ID)를 알고 있어, 이를 통해 부모 프로세스와의 통신이 가능하다.

다만, 통신이 가능할 뿐이지, 부모 프로세스와 자식 프로세스는 엄연히 서로 다른 프로세스로 **독립적으로 실행** 되며, **`독립적인 메모리 공간`** 을 가지고 있어 서로 다른 작업을 수행한다. 

대표적인 예로 웹 브라우저의 상단 탭(Tab) 이나 새 창을 들 수 있다. 각 브라우저 탭은 `같은 브라우저 프로그램 실행`이지만, `각기 다른 사이트 실행`을 행하기 때문이다.

![image](https://github.com/lielocks/WIL/assets/107406265/f6ecb5f1-bf4a-4555-bcdd-c4a18ba3d33c)

이러한 브라우저 멀티 프로세스 원리를 확인하기 위한 간단한 실험도 가능하다. 
여러개의 탭을 띄운뒤, 하나의 탭에서 F12로 개발자 도구를 열고 콘솔 탭에 `while(1) {}` 무한 루프 코드를 실행 시켜보자. 

그러면 `해당 탭에서는 클릭도 안되고 먹통이 되는 현상` 을 경험할 수 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/0f6f0ea6-6c06-46a2-86e3-c0edf1615d0a)

하지만 다른 탭에는 정상적으로 브라우징이 가능하다. 

이는 **탭 마다 다른 프로세스로 동작** 하기 때문이다.

## 멀티 프로세스의 장점

**1. 프로그램 안전성**
멀티 프로세스는 **각 프로세스가 독립적인 메모리 공간** 을 가지므로, 
***한 프로세스가 비정상적으로 종료되어도 다른 프로세스에 영향을 주지 않는다.*** 
그래서 `프로그램 전체의 안전성을 확보`할 수 있다는 장점이 있다.

예를 들자면 크롬 브라우저에서 여러개의 탭을 띄우고 여러곳의 웹사이트를 방문해 서비스를 이용한다고 하자. 
이때 어느 한 탭의 웹사이트에서 무언가 잘못되어 먹통이 되었다. 

![image](https://github.com/lielocks/WIL/assets/107406265/3af9422f-8bab-4ad2-835b-a9b15dffb3c5)

아주 심각한 오류가 아닌 이상, 당장 그 브라우저 탭의 웹사이트는 이용을 못하겠지만, 다른 탭은 별 문제없이 이용이 가능할 것이다. 

이러한 이유는 **자식 프로세스가 여러개** 생성되어 **메모리에 별도로 관리**되기 때문이다.

![image](https://github.com/lielocks/WIL/assets/107406265/04cb9b99-3bba-451c-a3b5-fbb712de53ba)

<br>

**2. 프로그램 병렬성**
멀티 프로세스와 여러개의 CPU 코어를 활용하여 둘의 시너지를 합쳐, ***다중 CPU 시스템***에서 **각 프로세스를 병렬적으로 실행하여 성능을 향상** 시킬 수 있다. 
예를 들어 `이미지 처리나 비디오 인코딩`과 같은 작업을 **여러 개의 코어나 CPU에 분산시켜 빠르게 처리**할 수 있다.

다만, 이 부분은 멀티 프로세스 만의 장점이라기 보단, **멀티 프로세스와 멀티 스레드 둘의 장점**이 옳다. 
그리고 **`멀티 스레드`** 로 구성하는 것이 멀티 프로세스로 구성하는 것보다 **훨씬 효율적이고 빠르기 때문에,** 멀티 프로세스로 성능을 올리는 행위는 거의 없다고 보면 된다. 

이에 대해선 뒤의 멀티 스레드 파트에서 다시 다룬다.

![image](https://github.com/lielocks/WIL/assets/107406265/e1cd5a91-1830-4c71-9797-eb1c8b99bc83)

<br>

**3. 시스템 확장성**
멀티 프로세스는 **각 프로세스가 독립적**이므로, `새로운 기능이나 모듈을 추가하거나 수정`할때 다른 프로세스에 **`영향을 주지 않는다.`** 그래서 **시스템의 규모를 쉽게 확장** 할 수 있다.

이 부분에 대해서는 컴퓨터의 소프트웨어로 예시를 드는 것보다 네트워크의 서버(server)로 드는 것이 적절하기 때문에 잠시 `분산 서버`에 대해서 말해보겠다. 

대규모 웹 서비스에서는 `수많은 요청을 동시에 처리`하기 위해 여러대의 서버를 두고 **로드 밸런서(Load Balancer)** 와 같은 장비를 사용하여 ***클라이언트 요청 트래픽을 분산 시킨다.*** 

이때 여러대의 서버는 `컴퓨터를 여러개`를 말하는 것일 수도 있고, `하나의 성능 좋은 컴퓨터에 여러개의 서버 프로세스`를 두는 것을 말하기도 한다. 멀티 프로세스의 상황은 후자이다.

서버 프로그래밍을 해본 백엔드 개발자분들은 **서버 클러스터(cluster)**를 구성해본 적이 있을 것이다. 
**`하나의 컴퓨터에 여러개의 서버 프로세스`**를 띄움으로써 **요청을 분산**시키는 것이다. Node.js 진영에선 대표적으로 PM2 가 있다.
![image](https://github.com/lielocks/WIL/assets/107406265/7f5caf61-898b-4cc1-a3fb-008e347d78df)

이렇게 멀티 프로세스를 사용하여 여러 대의 서버에 요청을 분산시켜 처리함으로써, 시스템의 규모를 쉽게 확장할 수 있으며, 부가로 서버의 장애나 다운타임을 최소화할 수 있게 되는 것이다.

<br>

## 멀티 프로세스의 단점

### 1. Context Switching Overhead
멀티 태스킹(multi tasking)을 구성하는데 핵심 기술인 **컨텍스트 스위칭(context switching)** 과정에서 `성능 저하`가 올 수 있다. 

특히나 프로세스를 컨텍스트 스위칭 하면, 

CPU는 **`다음 프로세스의 정보를 불러오기 위해 메모리를 검색`**하고, **`CPU 캐시 메모리를 초기화`**하며, **`프로세스 상태를 저장`**하고, **`불러올 데이터를 준비`**해야 하기 때문에, 이로 인한 빈번한 Context Switching 작업으로 인해 비용 **`오버헤드가 발생`** 할 수 있게 된다. 

반면 스레드를 컨텍스트 스위칭하면 프로세스 스위칭 보다 가벼워 훨씬 빠르고 좋다.

![image](https://github.com/lielocks/WIL/assets/107406265/5fe340cf-c664-4ae2-900a-8e90d2a31c9e)

따라서, 멀티 프로세스 환경에서는 Context Switching Overhead를 최소화하는 방법이 중요하다. 

이를 위해서 

+ 프로세스 수를 적정하게 유지하거나,

+ **I/O 바운드 작업** 이 많은 프로세스와 **CPU 바운드 작업** 이 많은 프로세스를 분리하여 관리하고,

+ **CPU 캐시를 효율적으로 활용** 하는 등의 방법을 고려해 봐야 한다.

<br>

### 2. 자원 공유 비효율성
멀티 프로세스는 각 프로세스가 **독립적인 메모리 공간** 을 가지므로, **`결과적으로 메모리 사용량이 증가`** 하게 된다.

만일 **`각 프로세스 간에 자원 공유`** 가 필요할 경우 프로세스 사이의 어렵고 복잡한 통신 기법인 **IPC(Inter-Process Commnuication)** 을 사용하여야 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/04ccd3fe-9d2f-470f-945c-13acac98e648)

IPC란 **운영체제 상에서 실행 중인 프로세스 간에 정보를 주고받는 메커니즘** 을 말한다. 

이를 위해 `파이프, 소켓, 메세지 큐` 등 다양한 방법이 사용된다. 

그런데 **`IPC 자체로 오버헤드가 발생`** 한다. 

예를 들어, `파이프나 소켓과 같은 IPC 기법`은 *데이터를 복사* 하거나 *버퍼링하는 과정* 에서 **성능 저하** 가 발생할 수 있기 때문이다. 또한 코드의 복잡도를 증가시킨다.

<br>

## Multi Thread
스레드는 **하나의 프로세스 내** 에 있는 `실행 흐름`이다. 

그리고 멀티 스레드는 **하나의 프로세스 안에 여러개의 스레드** 가 있는 것을 말한다. 
따라서 `하나의 프로그램`에서 `두가지 이상의 동작을 동시에` 처리하도록 하는 행위가 가능해진다.

**웹 서버**는 대표적인 멀티 스레드 응용 프로그램이다. 
사용자가 `서버 데이터베이스에 자료를 요청하는 동안` ***브라우저의 다른 기능을 이용*** 할 수 있는 이유도 바로 멀티 스레드 기능 덕분인 것이다. 

즉, **`하나의 스레드가 지연`** 되더라도, **다른 스레드는 작업을 지속** 할 수 있게 된다.

![image](https://github.com/lielocks/WIL/assets/107406265/bdbfd1c7-fc8d-4536-ac6d-6ea31f31f380)

멀티 프로세스와의 차이점을 부각시키기 위해, 멀티 프로세스를 설명할때 예시를 들었던 웹 브라우저를 다시 들어보겠다. 

**`멀티 프로세스`** 는 웹 브라우저에서의 **여러 탭이나 여러 창** 이라고 말했었다. 

대신 **`멀티 스레드`** 는 웹 브라우저의 **단일 탭** 또는 **창 내에서 브라우저 이벤트 루프, 네트워크 처리, I/O 및 기타 작업을 관리하고 처리** 하는데 사용된다고 보면된다.

<br>

## 멀티 스레드의 장점
윈도우, 리눅스 등 많은 운영체제들이 멀티 프로세싱을 지원하고 있지만 멀티 스레딩을 기본으로 하고 있다.

**왜 멀티 프로세스보다 `멀티 스레드` 로 프로그램을 돌리는 것이 유리한지** 그 이유에 대해 알아보자.

(이는 스레드 자체의 장점)

<br>

### 1. 스레드는 프로세스보다 가벼움
일단 스레드는 프로세스 보다 **용량이 가볍다.**

그도 그럴게 스레드는 **프로세스 내에서 생성**되기 때문에 ***스레드의 실행 환경을 설정하는 작업이 매우 간단*** 하여 `생성 및 종료가 빠르다.`

또한 스레드는 프로세스와 달리, **`코드, 데이터, 스택 영역을 제외한 나머지 자원`**을 **서로 공유** 하기 때문에 `기본적으로 내장되어 있는 데이터 용량`이 프로세스보다 당연히 작다. 

그래서 **`스레드를 생성하고 제거할 때,`** **프로세스 내부의 자원만을 관리**하면 되기 때문에 프로세스 생성, 제거 보다 **훨씬 빠른 것** 이다.

<br>

### 2. 자원의 효율성
멀티 스레드는 하나의 프로세스 내에서 여러 개의 스레드를 생성되기 때문에, **heap 영역과 같은 공유 메모리** 에 대해 **`스레드 간에 자원을 공유`** 가 가능하다. 

이를 통해, **`프로세스 간 통신 (IPC)을 사용하지 않고`** **데이터를 공유**할 수 있기 때문에, 자원의 효율적인 활용이 가능해 시스템 자원 소모가 줄어든다.

![image](https://github.com/lielocks/WIL/assets/107406265/f837f733-6fb6-403b-951e-2e588bb9de69)

<br>

### 3. Context Switching 비용 감소

스레드에도 컨텍스트 스위칭 오버헤드가 존재한다.
하지만 상대적으로 프로세스 컨텍스트 스위칭 오버헤드보다 훨씬 낮아 비용이 낮다는 장점이 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/0a09d578-8499-47be-8188-0f783176757b)

**`프로세스 컨텍스트 스위칭 비용`** 은 스위칭할 때마다 ***CPU 캐시에 있는 내용을 모두 초기화*** 하고, ***새로운 프로세스 정보를 CPU 캐시에 적재*** 해야 하므로 `높은 비용`이 든다. 

반면, **`스레드 컨텍스트 스위칭 비용`** 은 스위칭할 때 스레드 간에 공유하는 자원을 제외한 **스레드 정보(stack, register)만을 교체** 하면 되므로 프로세스 컨텍스트 스위칭 비용보다 상대적으로 낮은 것이다.

>
> **[ 컨텍스트 스위칭이 빨라진 스레드와 캐쉬 적중 ]**
>
> 쓰레드는 **공유하는 영역이 많기 때문에** 컨텍스트 스위칭이 **`빠르다`**
>
> 캐쉬는 CPU 와 Main Memory 사이에 위치하며 CPU 에서 한번 이상 읽어들인 메모리의 데이터를 저장하고 있다가, CPU 가 다시 그 메모리에 저장된 데이터를 요구할 때, Main Memory 를 통하지 않고 데이터를 전달해주는 용도이다.
>
> ***프로세스 컨텍스트 스위칭이 일어났을 경우, 공유하는 데이터가 없으므로 cache 가 지금껏 쌓아놓은 데이터들이 무너지고 새로 캐쉬 정보를 쌓아야 한다.***
>
> 이것이 **프로세스 컨텍스트 스위칭에 부담이 되는 요소이다.**
>
> 반면, 쓰레드라면 저장된 캐쉬 데이터는 쓰레드가 바뀌어도 공유하는 데이터가 있으므로 의미있다.
>
> 그럼므로 **스레드 컨텍스트 스위칭이 빠른 것** 이다.

<br>

### 4. 응답 시간 단축

앞의 멀티 스레드의 장점을 종합해보자면, 멀티 스레드는 **스레드 간의 통신이나 자원 공유**가 더욱 용이하며, 프로세스 보다 **가벼워 컨텍스트 스위칭 오버헤드도 작다.** 

따라서 멀티 프로세스 보다 ***응답 시간이 빠르다.***

예를 들어, 웹 서버에서 클라이언트 요청을 처리하는 경우, 

**`멀티 프로세스 방식`** 에서는 각 요청마다 프로세스를 생성하여 처리해야 하므로, 오버헤드가 크지만, **`멀티 스레드 방식`** 에서는 **여러 개의 스레드가 하나의 프로세스 내에서 요청을 처리**할 수 있으므로, **오버헤드가 감소해 더욱 빠른 응답 시간**을 보장할 수 있는 것이다.

이러한 이유로, `멀티 프로세서 환경`에서 `멀티 스레드`를 사용하여 작업을 처리하는 것이 `멀티 프로세스`를 사용하는 것보다 더 효율적이다라고 말할 수 있다.

<br>

## 멀티 스레드의 단점

### 1. 안정성 문제
멀티 프로세스 모델에서는 각 프로세스가 독립적으로 동작하므로 하나의 프로세스에서 문제가 발생해도 다른 프로세스들은 영향을 받지 않기 때문에 프로그램이 죽지 않고 계속 동작할 수 있다. 

그러나 멀티 스레드 모델에서는 ***기본적으로 하나의 스레드에서 문제가 발생하면*** 다른 스레드들도 영향을 받아 **전체 프로그램이 종료** 될 수 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/eb68ee60-589b-4df7-8f94-aa6af317028b)

물론 이는 프로그래머의 역량에 따라 극복할 수 가 있다. 

예를들어 스레드에 에러가 발생할 경우 이에 대한 `적절한 예외 처리`를 잘 해놓는다던지, 에러 발생 시 `새로운 스레드를 생성`하거나 `스레드 풀(Thread Pool)에서 잔여 스레드`를 가져오던지 하여 **프로그램 종료를 방지** 할 수 있다. 

다만, 이때 **새로운 스레드 생성** 이나 **놀고 있는 스레드 처리** 에 `추가 비용`이 발생하게 된다.

<br>

### 2. 동기화로 인한 성능 저하
멀티 스레드 모델은 **여러 개의 스레드가 공유 자원에 동시에 접근** 할 수 있기 때문에, **`동기화 문제`** 가 발생할 수 있다. 

예를들어 `여러 스레드가 동시에 한 자원을 변경`해 버린다면 **의도되지 않은 엉뚱한 값** 을 읽어 `서비스에 치명적인 버그`가 생길수도 있다. 따라서 **스레드 간 동기화(syncronized)**는 **데이터 접근을 제어** 하기 위한 필수적인 기술이다. 

동기화 작업은 **`여러 스레드들이 자원에 대한 접근`** 을 **순차적으로 통제** 하는 것이다. 

그러면 동시 접근으로 인한 동시 수정과 같은 현상은 일어나지 않게 된다. 

그러나 동기화 작업은  ***여러 스레드 접근을 제한***하는 것이기 때문에 **`병목 현상`** 이 일어나 **성능이 저하**될 가능성이 높다는 단점이 있다.

![image](https://github.com/lielocks/WIL/assets/107406265/a4b927f7-a030-4b62-891c-d029aaa0abea)

이를 해결하기 위해 임계 영역(Critical Section)에 대하여 뮤텍스(mutex), 또는 세마포어(Semaphore) 방식을 활용한다.

>
> **임계 영역 Critical Section**
> - 멀티 스레드 프로그래밍에서 임계 영역은 **공유 자원을 접근하는 코드 영역** 을 말한다. 대표적으로 전역 변수나 heap 메모리 영역을 들 수 있겠다.
>
> **뮤텍스 Mutex**
> - 공유 자원에 대한 **접근을 제어하기 위한 상호 배제 기법** 중 하나
> - 임계 영역에 진입하기 전에 **lock 을 획득** 하고, 임계 영역을 빠져나올 때 **lock 을 해제** 하여 다른 스레드들이 접근할 수 있도록 한다.
> - 한마디로 **`오직 1개의 스레드만이 공유 자원에 접근`** 할 수 있도록 제어하는 기법이다.
>
> **세마포어 Semaphore**
> - 세마포어는 **동시에 접근 가능한 스레드의 개수를 지정**할 수 있다.
> - **`세마포어 값이 1`** 이면 **뮤텍스와 동일한 역할**을 하며, **`값이 2 이상`** 이면 **동시에 접근 가능한 스레드의 수를 제어**할 수 있다.
> - 스레드가 *임계 영역에 진입하기 전*에 **세마포어 값을 확인**하고, ***값이 허용된 범위 내에 있을때만 락을 획득*** 할 수 있는 형식이다. 한마디로 뮤텍스 상위 호환이라고 보면 된다.

<br>

### 3. 데드락 (교착 상태)
Deadlock 이란, `다수의 프로세스나 스레드`가 **서로 자원을 점유** 하고, `다른 프로세스나 스레드가 점유한 자원을 기다리는 상황`에서 발생하는 **교착 상태** 를 말한다. 

여러 개의 스레드가 서로 대기하면서 무한정 기다리게되는 **무한 루프**와 같은 증상이라고 보면된다.

예를들어, **`스레드 1 은 자원 A을 점유하고 있는 상태에서 자원 B가 필요`** 한 상황이다. 
그리고 **`스레드 2 는 자원 B를 점유하고 있는 상태에서 자원 A이 필요한 상황`** 이다. 

하지만 **스레드 1은 자원 B가 필요한 상황에서 자원 A을 빌려줄 수 있는 상황이 아니고,** 
**스레드 2또한 자원 A이 필요한 상태에서 자원 B를 빌려줄 수 없는 상황**인 것이다.

이처럼 다수의 쓰레드가 **같은 lock** 을 동시에, ***다른 명령에 의해 획득하려 할 때 서로 절대 불가능한 일을 계속적으로 기다리는 상황*** 을 이야기 한다. 

![image](https://github.com/lielocks/WIL/assets/107406265/5acf5380-ed6e-469c-af62-41a78a38b0d6)

이러한 현상은 스레드의 특징인 **공유 자원에 대한 동시 엑세스** 로 인한 문제로, 

이를 방지하기 위한 상호배제(Mutual Exclusion), 점유와 대기(Hold and Wait), 비선점(No Preemption), 순환 대기(Circular Wait) 등의 알고리즘을 통해 극복해야 한다.

다만, 데드락은 멀티 스레드만의 단점이라기 보다는 **멀티 프로세스와 스레드 모델의 공통된 문제점**이라고 말하는 것이 옳다. 

왜냐하면 **프로세스 끼리는 기본적으로 독립적인 메모리 공간** 이지만 **`IPC를 통해 공유 자원을 사용`** 할 수 있기 때문에 ***멀티 스레드와 똑같이 교착 상태*** 에 빠질 수 있기 때문이다.

<br>

### 4. 그래도 Context Switching Overhead
앞서 멀티 프로세스보다 멀티 스레드의 컨텍스트 스위칭 오버헤드가 작아 성능에 유리하다라고 설명했었지만, **그래도 컨텍스트 스위칭 오버헤드 비용** 자체를 무시할수는 없다. 

특히나 **`스레드 수가 많으면 많을수록 그만큼 컨텍스트 스위칭이 많이 발생`** 되게 되고 당연히 이는 **성능 저하**로 이어진다.

이 부분은 '스레드를 많이 쓸수록 항상 성능이 좋아질까?' 라는 물음으로 던질 수 있다. 

보통 사람들이 생각하기에는 스레드가 많으면 많을 수록 그만큼 동시 처리수가 늘어나 당연히 스레드가 많으면 무조건 좋다고 이야기할 것이다. 

하지만 '컨텍스트 스위칭 오베허드'라는 개념을 알고 있는 개발자인 우리들은 '과연 꼭 그럴까?' 라는 의문을 던져야 한다.

<br>

### 5. 디버깅이 어려움
멀티 스레드를 사용하면, **여러 개의 스레드가 동시에 실행** 되기 때문에, **각 스레드의 동작을 추적하기 어려울 수 있다.** 

예를들어 코드를 디버깅하는 도중에 `다른 스레드가 실행되어 예기치 않은 결과`가 발생할 수 있다. 

또한 **어떤 스레드가 언제 어떤 자원에 접근**하고, **어떤 순서로 실행되는지** 등을 파악하기 어려울 수 있다.

따라서 스레드 간의 상호작용과 동기화 기법을 잘 이해하고, 디버깅 도구를 적극적으로 활용해야 한다.

![image](https://github.com/lielocks/WIL/assets/107406265/a0632afe-21d4-427f-a633-757a692d97a5)

<br>

### 6. 운영체제의 지원이 필요
오늘날의 윈도우, 리눅스, 맥 OS에선 모두 기본적으로 멀티 스레딩을 기본적으로 지원하도록 설계 되었으니 문제점이라기에는 약간 어폐가 있긴 하다. 

하지만, 1980년대의 SunOS3와 같은 오래된 유닉스 시스템에는 스레드가 없었고 프로세스만 있는, 멀티 스레딩을 지원하지 않는 운영 체제가 있었기 때문에 멀티 스레드의 단점으로 넣어 보았다. (생략해도 상관 없다.)


